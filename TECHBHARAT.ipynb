{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad774e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import zipfile\n",
    "import io\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import shutil\n",
    "from IPython.display import display, HTML, Image\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('rtgs_system.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d27748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:39:53,999 - INFO - Created directory: rtgs_outputs\n",
      "2025-09-07 19:39:54,000 - INFO - Created directory: rtgs_outputs/standardized\n",
      "2025-09-07 19:39:54,001 - INFO - Created directory: rtgs_outputs/cleaned\n",
      "2025-09-07 19:39:54,002 - INFO - Created directory: rtgs_outputs/insights\n",
      "2025-09-07 19:39:54,003 - INFO - Created directory: rtgs_outputs/logs\n",
      "2025-09-07 19:39:54,004 - INFO - Created directory: rtgs_outputs/visualizations\n",
      "2025-09-07 19:39:54,005 - INFO - Created directory: rtgs_outputs/models\n",
      "2025-09-07 19:39:54,006 - INFO - Created directory: rtgs_outputs/reports\n",
      "2025-09-07 19:39:54,006 - INFO - Created directory: rtgs_outputs/exports\n",
      "2025-09-07 19:39:54,007 - INFO - Created directory: rtgs_outputs/interactive\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration and directories set up successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration class and directory setup\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the RTGS system with enhanced visualization settings\"\"\"\n",
    "    \n",
    "    \n",
    "    DATA_PATH = r\"C:\\Users\\maverick\\TECHBHARAT\\TECHBHARAT CLEAN DATA FILE.csv\"\n",
    "    OUTPUT_DIR = \"rtgs_outputs\"\n",
    "    \n",
    "    \n",
    "    DATE_FORMAT = \"%Y-%m-%d\"\n",
    "    STANDARDIZED_COLUMNS = {\n",
    "        'rainfall': 'rain_mm',\n",
    "        'temperature': 'temp_c',\n",
    "        'humidity': 'humidity_pct',\n",
    "        'wind': 'wind_kmph'\n",
    "    }\n",
    "    \n",
    "   \n",
    "    OUTLIER_THRESHOLD = 3  \n",
    "    MISSING_DATA_THRESHOLD = 0.3 \n",
    "    \n",
    "   \n",
    "    RISK_THRESHOLDS = {\n",
    "        'low': 30,\n",
    "        'medium': 70,\n",
    "        'high': 100\n",
    "    }\n",
    "    \n",
    "   \n",
    "    COLORS = {\n",
    "        'low_risk': '#2ecc71',    # Green\n",
    "        'medium_risk': '#f39c12', # Orange\n",
    "        'high_risk': '#e74c3c',   # Red\n",
    "        'rainfall': '#3498db',    # Blue\n",
    "        'temperature': '#e74c3c', # Red\n",
    "        'humidity': '#9b59b6',    # Purple\n",
    "        'wind': '#34495e'         # Dark blue\n",
    "    }\n",
    "    \n",
    "   \n",
    "    CHART_WIDTH = 1000\n",
    "    CHART_HEIGHT = 600\n",
    "    MAP_SETTINGS = {\n",
    "        'center': {'lat': 17.1232, 'lon': 79.2088},  # Center of Telangana\n",
    "        'zoom': 6,\n",
    "        'style': 'open-street-map'\n",
    "    }\n",
    "    \n",
    "   \n",
    "    JOIN_KEYS = ['district', 'date', 'season']\n",
    "    \n",
    "    \n",
    "    MODEL_PARAMS = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "   \n",
    "    INTERACTIVE_FILTERS = {\n",
    "        'district': 'All',\n",
    "        'season': 'All',\n",
    "        'year_range': [2010, 2023],\n",
    "        'risk_level': 'All'\n",
    "    }\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Create all necessary output directories\"\"\"\n",
    "    directories = [\n",
    "        Config.OUTPUT_DIR,\n",
    "        f\"{Config.OUTPUT_DIR}/standardized\",\n",
    "        f\"{Config.OUTPUT_DIR}/cleaned\", \n",
    "        f\"{Config.OUTPUT_DIR}/insights\",\n",
    "        f\"{Config.OUTPUT_DIR}/logs\",\n",
    "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
    "        f\"{Config.OUTPUT_DIR}/models\",\n",
    "        f\"{Config.OUTPUT_DIR}/reports\",\n",
    "        f\"{Config.OUTPUT_DIR}/exports\",\n",
    "        f\"{Config.OUTPUT_DIR}/interactive\"\n",
    "    ]\n",
    "\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        logger.info(f\"Created directory: {directory}\")\n",
    "\n",
    "\n",
    "setup_directories()\n",
    "print(\"Configuration and directories set up successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfed67ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset analysis functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataset analysis functions\n",
    "def get_dataset_info(file_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Get comprehensive information about the dataset with visual analysis\"\"\"\n",
    "    logger.info(f\"Analyzing dataset: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        df_sample = pd.read_csv(file_path, nrows=10000)\n",
    "        \n",
    "       \n",
    "        info = {\n",
    "            'file_path': file_path,\n",
    "            'size_mb': os.path.getsize(file_path) / (1024 * 1024),\n",
    "            'total_rows': sum(1 for line in open(file_path, encoding=\"utf-8\")) - 1,\n",
    "            'sample_rows': len(df_sample),\n",
    "            'columns': list(df_sample.columns),\n",
    "            'dtypes': {col: str(dtype) for col, dtype in df_sample.dtypes.to_dict().items()},\n",
    "            'date_columns': [col for col in df_sample.columns if 'date' in col.lower()],\n",
    "            'numeric_columns': df_sample.select_dtypes(include=[np.number]).columns.tolist(),\n",
    "            'categorical_columns': df_sample.select_dtypes(include=['object']).columns.tolist(),\n",
    "            'missing_values': df_sample.isnull().sum().to_dict(),\n",
    "            'memory_usage_mb': df_sample.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "        }\n",
    "        \n",
    "       \n",
    "        create_data_structure_visualizations(df_sample, info)\n",
    "        \n",
    "        \n",
    "        with open(f\"{Config.OUTPUT_DIR}/logs/dataset_info.json\", 'w') as f:\n",
    "            json.dump(info, f, indent=4)\n",
    "            \n",
    "        logger.info(f\"Dataset analysis complete. Found {info['total_rows']} rows and {len(info['columns'])} columns.\")\n",
    "        return info\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error analyzing dataset: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def create_data_structure_visualizations(df_sample: pd.DataFrame, info: Dict[str, Any]):\n",
    "    \"\"\"Create visualizations showing data structure and quality\"\"\"\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    \n",
    "    dtype_counts = df_sample.dtypes.value_counts()\n",
    "    axes[0, 0].pie(dtype_counts.values, labels=dtype_counts.index.astype(str), autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Data Types Distribution')\n",
    "    \n",
    "    \n",
    "    missing_values = df_sample.isnull().sum()\n",
    "    missing_values = missing_values[missing_values > 0]\n",
    "    if len(missing_values) > 0:\n",
    "        axes[0, 1].bar(range(len(missing_values)), missing_values.values)\n",
    "        axes[0, 1].set_xticks(range(len(missing_values)))\n",
    "        axes[0, 1].set_xticklabels(missing_values.index, rotation=45, ha='right')\n",
    "        axes[0, 1].set_title('Missing Values by Column')\n",
    "        axes[0, 1].set_ylabel('Missing Count')\n",
    "    \n",
    "  \n",
    "    if info['numeric_columns']:\n",
    "        numeric_data = df_sample[info['numeric_columns']].describe().T\n",
    "        axes[1, 0].scatter(numeric_data['mean'], numeric_data['std'], alpha=0.5)\n",
    "        for i, col in enumerate(numeric_data.index):\n",
    "            axes[1, 0].annotate(col, (numeric_data['mean'].iloc[i], numeric_data['std'].iloc[i]))\n",
    "        axes[1, 0].set_xlabel('Mean')\n",
    "        axes[1, 0].set_ylabel('Standard Deviation')\n",
    "        axes[1, 0].set_title('Numeric Columns: Mean vs Standard Deviation')\n",
    "    \n",
    "\n",
    "    if info['categorical_columns']:\n",
    "        cardinality = [df_sample[col].nunique() for col in info['categorical_columns']]\n",
    "        axes[1, 1].bar(range(len(cardinality)), cardinality)\n",
    "        axes[1, 1].set_xticks(range(len(cardinality)))\n",
    "        axes[1, 1].set_xticklabels(info['categorical_columns'], rotation=45, ha='right')\n",
    "        axes[1, 1].set_title('Categorical Columns Cardinality')\n",
    "        axes[1, 1].set_ylabel('Unique Values Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/data_structure_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "   \n",
    "    if len(info['numeric_columns']) > 1:\n",
    "        corr_matrix = df_sample[info['numeric_columns']].corr()\n",
    "        fig = px.imshow(corr_matrix, \n",
    "                       title='Correlation Matrix of Numeric Features',\n",
    "                       color_continuous_scale='RdBu_r',\n",
    "                       aspect='auto')\n",
    "        fig.write_html(f\"{Config.OUTPUT_DIR}/visualizations/correlation_matrix.html\")\n",
    "        \n",
    "        # Also save as static image\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0)\n",
    "        plt.title('Correlation Matrix of Numeric Features')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/correlation_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "print(\"Dataset analysis functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3b69a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data standardization functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data standardization functions\n",
    "def get_season(month: int) -> str:\n",
    "    \"\"\"Get season from month number\"\"\"\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Summer'\n",
    "    elif month in [6, 7, 8, 9]:\n",
    "        return 'Monsoon'\n",
    "    else:\n",
    "        return 'Post-Monsoon'\n",
    "\n",
    "def load_and_standardize_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and standardize the dataset with progress tracking and validation\"\"\"\n",
    "    logger.info(\"Loading and standardizing data...\")\n",
    "    \n",
    " \n",
    "    progress_data = {\n",
    "        'start_time': datetime.now(),\n",
    "        'steps': [],\n",
    "        'issues_found': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "       \n",
    "        chunk_size = 100000\n",
    "        chunks = []\n",
    "        total_rows = sum(1 for line in open(file_path, encoding=\"utf-8\")) - 1\n",
    "        \n",
    "        for i, chunk in enumerate(pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)):\n",
    "            chunks.append(chunk)\n",
    "            progress = min((i + 1) * chunk_size / total_rows * 100, 100)\n",
    "            if i % 10 == 0:  # Log every 10 chunks\n",
    "                logger.info(f\"Loading data: {progress:.1f}% complete\")\n",
    "        \n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "        original_shape = df.shape\n",
    "        progress_data['steps'].append({\n",
    "            'step': 'data_loading',\n",
    "            'status': 'completed',\n",
    "            'rows_loaded': len(df),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Original data shape: {original_shape}\")\n",
    "        \n",
    "     \n",
    "        df.columns = [col.lower().replace(' ', '_').replace('(', '').replace(')', '') for col in df.columns]\n",
    "        \n",
    "    \n",
    "        date_cols = [col for col in df.columns if 'date' in col]\n",
    "        if date_cols:\n",
    "            date_col = date_cols[0]\n",
    "            for date_format in ['%Y-%m-%d', '%d-%m-%Y', '%m/%d/%Y', '%Y/%m/%d', '%d-%b-%y', '%d/%m/%y']:\n",
    "                try:\n",
    "                    df['date'] = pd.to_datetime(df[date_col], format=date_format, errors='raise')\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                \n",
    "                df['date'] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                progress_data['issues_found'].append('date_parsing_used_coercion')\n",
    "            \n",
    "            \n",
    "            invalid_dates = df['date'].isna().sum()\n",
    "            if invalid_dates > 0:\n",
    "                df = df.dropna(subset=['date'])\n",
    "                progress_data['issues_found'].append(f'dropped_{invalid_dates}_invalid_dates')\n",
    "        \n",
    "        \n",
    "        time_features_added = []\n",
    "        if 'date' in df.columns:\n",
    "            df['year'] = df['date'].dt.year\n",
    "            df['month'] = df['date'].dt.month\n",
    "            df['day'] = df['date'].dt.day\n",
    "            df['day_of_year'] = df['date'].dt.dayofyear\n",
    "            df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "            df['quarter'] = df['date'].dt.quarter\n",
    "            df['season'] = df['month'].apply(get_season)\n",
    "            time_features_added = ['year', 'month', 'day', 'day_of_year', 'week_of_year', 'quarter', 'season']\n",
    "        \n",
    "        \n",
    "        if 'district' in df.columns:\n",
    "            df['district'] = df['district'].str.title().str.strip()\n",
    "            district_stats = {\n",
    "                'unique_districts': df['district'].nunique(),\n",
    "                'most_common_district': df['district'].mode().iloc[0] if len(df['district'].mode()) > 0 else None\n",
    "            }\n",
    "            progress_data['district_stats'] = district_stats\n",
    "        \n",
    "        \n",
    "        numeric_indicators = ['rain', 'temp', 'humidity', 'wind']\n",
    "        conversion_issues = {}\n",
    "        \n",
    "        for col in df.columns:\n",
    "            for indicator in numeric_indicators:\n",
    "                if indicator in col and df[col].dtype == 'object':\n",
    "                    try:\n",
    "                        \n",
    "                        original_non_null = df[col].notna().sum()\n",
    "                        \n",
    "                      \n",
    "                        df[col] = pd.to_numeric(df[col].astype(str).str.replace('[^0-9.-]', '', regex=True), errors='coerce')\n",
    "                        \n",
    "                       \n",
    "                        new_non_null = df[col].notna().sum()\n",
    "                        if new_non_null < original_non_null:\n",
    "                            conversion_issues[col] = original_non_null - new_non_null\n",
    "                    except Exception as e:\n",
    "                        progress_data['issues_found'].append(f'conversion_error_{col}: {str(e)}')\n",
    "        \n",
    "        if conversion_issues:\n",
    "            progress_data['conversion_issues'] = conversion_issues\n",
    "        \n",
    "        \n",
    "        df.to_parquet(f\"{Config.OUTPUT_DIR}/standardized/data_standardized.parquet\", index=False)\n",
    "        df.to_csv(f\"{Config.OUTPUT_DIR}/standardized/data_standardized.csv\", index=False)\n",
    "        \n",
    "        logger.info(f\"Standardization complete. Final shape: {df.shape}\")\n",
    "        \n",
    "        \n",
    "        standardization_report = {\n",
    "            'original_shape': original_shape,\n",
    "            'final_shape': df.shape,\n",
    "            'columns_standardized': list(df.columns),\n",
    "            'time_features_added': time_features_added,\n",
    "            'date_range': {\n",
    "                'start': df['date'].min().strftime(Config.DATE_FORMAT) if 'date' in df.columns else None,\n",
    "                'end': df['date'].max().strftime(Config.DATE_FORMAT) if 'date' in df.columns else None\n",
    "            },\n",
    "            'districts': sorted(df['district'].unique()) if 'district' in df.columns else [],\n",
    "            'missing_values_post_standardization': df.isnull().sum().to_dict(),\n",
    "            'data_quality_issues': progress_data['issues_found'],\n",
    "            'processing_time_seconds': (datetime.now() - progress_data['start_time']).total_seconds()\n",
    "        }\n",
    "        \n",
    "        with open(f\"{Config.OUTPUT_DIR}/logs/standardization_report.json\", 'w') as f:\n",
    "            json.dump(standardization_report, f, indent=4)\n",
    "        \n",
    "      \n",
    "        create_standardization_visualization(df, standardization_report)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in standardization process: {str(e)}\")\n",
    "        progress_data['steps'].append({\n",
    "            'step': 'error',\n",
    "            'error_message': str(e),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        raise\n",
    "\n",
    "def create_standardization_visualization(df: pd.DataFrame, report: Dict[str, Any]):\n",
    "    \"\"\"Create visualizations showing the standardization process\"\"\"\n",
    "    \n",
    "   \n",
    "    if 'missing_values_pre_clean' in report and 'missing_values_post_standardization' in report:\n",
    "        missing_before = report['missing_values_pre_clean']\n",
    "        missing_after = report['missing_values_post_standardization']\n",
    "        \n",
    "       \n",
    "        columns = list(missing_before.keys())\n",
    "        before_vals = [missing_before[col] for col in columns]\n",
    "        after_vals = [missing_after[col] for col in columns]\n",
    "        \n",
    "        x = np.arange(len(columns))\n",
    "        width = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        rects1 = ax.bar(x - width/2, before_vals, width, label='Before Standardization', alpha=0.8)\n",
    "        rects2 = ax.bar(x + width/2, after_vals, width, label='After Standardization', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Columns')\n",
    "        ax.set_ylabel('Missing Values Count')\n",
    "        ax.set_title('Missing Values Before and After Standardization')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(columns, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/missing_values_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    if 'date' in df.columns:\n",
    "        time_series_data = df.groupby('date').size().reset_index(name='count')\n",
    "        \n",
    "        fig = px.line(time_series_data, x='date', y='count', \n",
    "                     title='Data Points Over Time',\n",
    "                     labels={'count': 'Number of Records', 'date': 'Date'})\n",
    "        fig.write_html(f\"{Config.OUTPUT_DIR}/visualizations/temporal_coverage.html\")\n",
    "        \n",
    "       \n",
    "        if 'season' in df.columns:\n",
    "            seasonal_data = df.groupby(['year', 'season']).size().unstack(fill_value=0)\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            seasonal_data.plot(kind='bar', stacked=True)\n",
    "            plt.title('Data Distribution by Season and Year')\n",
    "            plt.xlabel('Year')\n",
    "            plt.ylabel('Number of Records')\n",
    "            plt.legend(title='Season')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/seasonal_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "print(\"Data standardization functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5a664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and transformation functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Data cleaning and transformation functions\n",
    "def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create advanced derived features for analysis\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "\n",
    "    if 'temp_min' in df.columns and 'temp_max' in df.columns:\n",
    "        df['avg_temp'] = (df['temp_min'] + df['temp_max']) / 2\n",
    "    \n",
    "    if 'humidity_min' in df.columns and 'humidity_max' in df.columns:\n",
    "        df['avg_humidity'] = (df['humidity_min'] + df['humidity_max']) / 2\n",
    "        \n",
    "    if 'wind_min' in df.columns and 'wind_max' in df.columns:\n",
    "        df['avg_wind'] = (df['wind_min'] + df['wind_max']) / 2\n",
    "    \n",
    "    \n",
    "    if 'rainfall_mm' in df.columns and 'district' in df.columns and 'date' in df.columns:\n",
    "        df = df.sort_values(['district', 'date'])\n",
    "        df['rolling_avg_rainfall_7d'] = df.groupby('district')['rainfall_mm'].transform(\n",
    "            lambda x: x.rolling(window=7, min_periods=1).mean()\n",
    "        )\n",
    "        df['rolling_avg_rainfall_30d'] = df.groupby('district')['rainfall_mm'].transform(\n",
    "            lambda x: x.rolling(window=30, min_periods=1).mean()\n",
    "        )\n",
    "    \n",
    "  \n",
    "    if 'rainfall_mm' in df.columns and 'district' in df.columns and 'season' in df.columns:\n",
    "        seasonal_rainfall = df.groupby(['district', 'season'])['rainfall_mm'].mean().reset_index()\n",
    "        seasonal_rainfall.rename(columns={'rainfall_mm': 'seasonal_avg_rainfall'}, inplace=True)\n",
    "        df = df.merge(seasonal_rainfall, on=['district', 'season'], how='left')\n",
    "    \n",
    "   \n",
    "    if 'rainfall_mm' in df.columns and 'seasonal_avg_rainfall' in df.columns:\n",
    "        df['rainfall_anomaly'] = df['rainfall_mm'] - df['seasonal_avg_rainfall']\n",
    "        df['rainfall_anomaly_pct'] = (df['rainfall_anomaly'] / df['seasonal_avg_rainfall']) * 100\n",
    "    \n",
    "  \n",
    "    if 'rainfall_mm' in df.columns:\n",
    "        df['heavy_rain_flag'] = (df['rainfall_mm'] > 50).astype(int)\n",
    "    \n",
    "    if 'avg_temp' in df.columns:\n",
    "        df['heatwave_flag'] = (df['avg_temp'] > 35).astype(int)\n",
    "    \n",
    " \n",
    "    if 'rainfall_mm' in df.columns and 'district' in df.columns and 'date' in df.columns:\n",
    "        df = df.sort_values(['district', 'date'])\n",
    "        df['dry_day'] = (df['rainfall_mm'] < 1).astype(int)\n",
    "        df['dry_spell_length'] = df.groupby('district')['dry_day'].transform(\n",
    "            lambda x: x * (x.groupby((x != x.shift()).cumsum()).cumcount() + 1)\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_enhanced_risk_indices(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create enhanced risk indices for agricultural assessment\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    \n",
    "    risk_factors = {}\n",
    "    \n",
    "    if 'rainfall_mm' in df.columns:\n",
    "        # Calculate rainfall risk (both deficit and excess)\n",
    "        df['rainfall_risk'] = np.where(\n",
    "            df['rainfall_mm'] < 5,  # Drought risk\n",
    "            (5 - df['rainfall_mm']) / 5 * 50,  # Scale 0-50 for drought\n",
    "            np.where(\n",
    "                df['rainfall_mm'] > 50,  # Flood risk\n",
    "                (df['rainfall_mm'] - 50) / 50 * 50,  # Scale 0-50 for flood\n",
    "                0  # No risk\n",
    "            )\n",
    "        )\n",
    "        risk_factors['rainfall_risk'] = 0.4  # Weight\n",
    "    \n",
    "    if 'avg_temp' in df.columns:\n",
    "        # Calculate temperature risk (heat stress)\n",
    "        df['temperature_risk'] = np.where(\n",
    "            df['avg_temp'] > 30,\n",
    "            (df['avg_temp'] - 30) / 10 * 50,  # Scale 0-50 for heat stress\n",
    "            0\n",
    "        )\n",
    "        risk_factors['temperature_risk'] = 0.3  # Weight\n",
    "    \n",
    "    if 'avg_humidity' in df.columns:\n",
    "        # Calculate humidity risk (both low and high)\n",
    "        df['humidity_risk'] = np.where(\n",
    "            df['avg_humidity'] < 40,  # Too dry\n",
    "            (40 - df['avg_humidity']) / 40 * 25,  # Scale 0-25 for dry\n",
    "            np.where(\n",
    "                df['avg_humidity'] > 80,  # Too humid\n",
    "                (df['avg_humidity'] - 80) / 20 * 25,  # Scale 0-25 for humid\n",
    "                0\n",
    "            )\n",
    "        )\n",
    "        risk_factors['humidity_risk'] = 0.2  # Weight\n",
    "    \n",
    "    if 'dry_spell_length' in df.columns:\n",
    "        # Calculate dry spell risk\n",
    "        df['dry_spell_risk'] = np.where(\n",
    "            df['dry_spell_length'] > 7,\n",
    "            np.minimum((df['dry_spell_length'] - 7) / 7 * 50, 50),  # Scale 0-50\n",
    "            0\n",
    "        )\n",
    "        risk_factors['dry_spell_risk'] = 0.1  \n",
    "    \n",
    "    \n",
    "    ari_components = []\n",
    "    for factor, weight in risk_factors.items():\n",
    "        if factor in df.columns:\n",
    "            ari_components.append(df[factor] * weight)\n",
    "    \n",
    "    if ari_components:\n",
    "        df['ari'] = sum(ari_components)\n",
    "        \n",
    "       \n",
    "        df['ari_normalized'] = (df['ari'] - df['ari'].min()) / (df['ari'].max() - df['ari'].min()) * 100\n",
    "        \n",
    "       \n",
    "        df['risk_category'] = pd.cut(\n",
    "            df['ari_normalized'],\n",
    "            bins=[0, 30, 70, 100],\n",
    "            labels=['Low', 'Medium', 'High'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_quality_flags(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add data quality flags to the dataset\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "   \n",
    "    required_cols = ['district', 'date', 'rainfall_mm']\n",
    "    df['data_completeness'] = df[required_cols].notnull().mean(axis=1) * 100\n",
    "    \n",
    "   \n",
    "    if 'temp_min' in df.columns and 'temp_max' in df.columns:\n",
    "        df['temp_consistency_flag'] = (df['temp_min'] <= df['temp_max']).astype(int)\n",
    "    \n",
    "    if 'humidity_min' in df.columns and 'humidity_max' in df.columns:\n",
    "        df['humidity_consistency_flag'] = (df['humidity_min'] <= df['humidity_max']).astype(int)\n",
    "    \n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    numeric_cols = [col for col in numeric_cols if col not in ['year', 'month', 'day', 'day_of_year', 'week_of_year', 'quarter']]\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        z_scores = np.abs(stats.zscore(df[col], nan_policy='omit'))\n",
    "        df[f'{col}_outlier_flag'] = (z_scores > Config.OUTLIER_THRESHOLD).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_and_transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean and transform the standardized data with advanced features\"\"\"\n",
    "    logger.info(\"Cleaning and transforming data...\")\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    cleaning_report = {\n",
    "        'initial_rows': int(len(df_clean)),\n",
    "        'initial_columns': int(len(df_clean.columns)),\n",
    "        'steps': [],\n",
    "        'anomalies_detected': {},\n",
    "        'processing_start_time': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "\n",
    "    duplicates = df_clean.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        df_clean = df_clean.drop_duplicates()\n",
    "        cleaning_report['duplicates_removed'] = duplicates\n",
    "        logger.info(f\"Removed {duplicates} duplicate rows.\")\n",
    "    \n",
    "  \n",
    "    missing_before = int(df_clean.isnull().sum().sum())\n",
    "    cleaning_report['missing_values_before'] = missing_before\n",
    "    \n",
    "   \n",
    "    if 'district' in df_clean.columns:\n",
    "        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            # Track original missing values\n",
    "            col_missing_before = df_clean[col].isnull().sum()\n",
    "            \n",
    "           \n",
    "            if col in ['rainfall_mm', 'temp_min', 'temp_max', 'humidity_min', 'humidity_max', 'wind_min', 'wind_max']:\n",
    "                # First try forward fill within each district\n",
    "                df_clean[col] = df_clean.groupby('district')[col].transform(\n",
    "                    lambda x: x.ffill().bfill()\n",
    "                )\n",
    "                \n",
    "               \n",
    "                still_missing = df_clean[col].isnull()\n",
    "                if still_missing.any() and 'season' in df_clean.columns:\n",
    "                    seasonal_avg = df_clean.groupby(['district', 'season'])[col].transform('mean')\n",
    "                    df_clean.loc[still_missing, col] = seasonal_avg[still_missing]\n",
    "            \n",
    "           \n",
    "            col_missing_after = df_clean[col].isnull().sum()\n",
    "            if col_missing_after < col_missing_before:\n",
    "                cleaning_report['steps'].append({\n",
    "                    'column': col,\n",
    "                    'missing_values_filled': col_missing_before - col_missing_after,\n",
    "                    'method': 'district_seasonal_imputation'\n",
    "                })\n",
    "    \n",
    "    missing_after = int(df_clean.isnull().sum().sum())\n",
    "    cleaning_report['missing_values_after'] = missing_after\n",
    "    cleaning_report['missing_values_reduction'] = missing_before - missing_after\n",
    "    logger.info(\"Missing values handled successfully.\")\n",
    "    \n",
    "   \n",
    "    outlier_report = {}\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col not in ['year', 'month', 'day', 'day_of_year', 'week_of_year', 'quarter']:\n",
    "            # Use multiple methods for outlier detection\n",
    "            z_scores = np.abs(stats.zscore(df_clean[col], nan_policy='omit'))\n",
    "            iqr = df_clean[col].quantile(0.75) - df_clean[col].quantile(0.25)\n",
    "            lower_bound_iqr = df_clean[col].quantile(0.25) - 1.5 * iqr\n",
    "            upper_bound_iqr = df_clean[col].quantile(0.75) + 1.5 * iqr\n",
    "            \n",
    "            # Detect outliers\n",
    "            z_outliers = np.where(z_scores > Config.OUTLIER_THRESHOLD)\n",
    "            iqr_outliers = np.where((df_clean[col] < lower_bound_iqr) | (df_clean[col] > upper_bound_iqr))\n",
    "            \n",
    "            outlier_report[col] = {\n",
    "                'z_score_outliers': int(len(z_outliers[0])),\n",
    "                'iqr_outliers': int(len(iqr_outliers[0])),\n",
    "                'total_values': int(len(df_clean[col])),\n",
    "                'outlier_percentage': float(len(z_outliers[0]) / len(df_clean[col]) * 100)\n",
    "            }\n",
    "            \n",
    "            \n",
    "            lower_cap = df_clean[col].quantile(0.01)\n",
    "            upper_cap = df_clean[col].quantile(0.99)\n",
    "            df_clean[col] = np.where(df_clean[col] < lower_cap, lower_cap, df_clean[col])\n",
    "            df_clean[col] = np.where(df_clean[col] > upper_cap, upper_cap, df_clean[col])\n",
    "            \n",
    "            cleaning_report['anomalies_detected'][col] = outlier_report[col]\n",
    "    \n",
    "    cleaning_report['outlier_analysis'] = outlier_report\n",
    "    logger.info(\"Outliers handled successfully.\")\n",
    "    \n",
    "    \n",
    "    df_clean = create_advanced_features(df_clean)\n",
    "    \n",
    "  \n",
    "    df_clean = create_enhanced_risk_indices(df_clean)\n",
    "    \n",
    "    \n",
    "    df_clean = add_quality_flags(df_clean)\n",
    "    \n",
    "    \n",
    "    df_clean.to_parquet(f\"{Config.OUTPUT_DIR}/cleaned/data_cleaned.parquet\", index=False)\n",
    "    df_clean.to_csv(f\"{Config.OUTPUT_DIR}/cleaned/data_cleaned.csv\", index=False)\n",
    "    \n",
    "    \n",
    "    cleaning_report['final_rows'] = int(len(df_clean))\n",
    "    cleaning_report['final_columns'] = int(len(df_clean.columns))\n",
    "    cleaning_report['processing_end_time'] = datetime.now().isoformat()\n",
    "    cleaning_report['processing_duration_seconds'] = (\n",
    "        datetime.fromisoformat(cleaning_report['processing_end_time']) - \n",
    "        datetime.fromisoformat(cleaning_report['processing_start_time'])\n",
    "    ).total_seconds()\n",
    "    \n",
    "    \n",
    "    with open(f\"{Config.OUTPUT_DIR}/logs/cleaning_report.json\", 'w') as f:\n",
    "        json.dump(cleaning_report, f, indent=4, default=str)\n",
    "    \n",
    "    \n",
    "    create_cleaning_visualization_report(cleaning_report, df_clean)\n",
    "    \n",
    "    logger.info(\"Data cleaning and transformation complete\")\n",
    "    return df_clean\n",
    "\n",
    "def create_cleaning_visualization_report(report: Dict[str, Any], df: pd.DataFrame):\n",
    "    \"\"\"Create visualizations showing the cleaning process\"\"\"\n",
    "    \n",
    "   \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(['Before Cleaning', 'After Cleaning'], \n",
    "           [report['missing_values_before'], report['missing_values_after']],\n",
    "           color=['#e74c3c', '#2ecc71'])\n",
    "    ax.set_ylabel('Missing Values Count')\n",
    "    ax.set_title('Missing Values Before and After Cleaning')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/missing_values_cleaning.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    if 'outlier_analysis' in report:\n",
    "        outlier_data = []\n",
    "        columns = []\n",
    "        z_outliers = []\n",
    "        iqr_outliers = []\n",
    "        \n",
    "        for col, stats in report['outlier_analysis'].items():\n",
    "            outlier_data.append({\n",
    "                'column': col,\n",
    "                'z_score_outliers': stats['z_score_outliers'],\n",
    "                'iqr_outliers': stats['iqr_outliers'],\n",
    "                'total_values': stats['total_values']\n",
    "            })\n",
    "            columns.append(col)\n",
    "            z_outliers.append(stats['z_score_outliers'])\n",
    "            iqr_outliers.append(stats['iqr_outliers'])\n",
    "        \n",
    "      \n",
    "        x = np.arange(len(columns))\n",
    "        width = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        rects1 = ax.bar(x - width/2, z_outliers, width, label='Z-Score Outliers', alpha=0.8)\n",
    "        rects2 = ax.bar(x + width/2, iqr_outliers, width, label='IQR Outliers', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Columns')\n",
    "        ax.set_ylabel('Outlier Count')\n",
    "        ax.set_title('Outliers Detected by Method')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(columns, rotation=45, ha='right')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/outlier_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "    if 'risk_category' in df.columns:\n",
    "        risk_counts = df['risk_category'].value_counts()\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Distribution of Risk Categories After Cleaning')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/risk_distribution_after_cleaning.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "print(\"Data cleaning and transformation functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02086aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insights generation functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Insights generation functions\n",
    "def generate_insights(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"Generate comprehensive insights from the data with predictive modeling\"\"\"\n",
    "    logger.info(\"Generating insights from data...\")\n",
    "\n",
    "    insights = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'basic_statistics': {},\n",
    "        'seasonal_analysis': {},\n",
    "        'district_analysis': {},\n",
    "        'risk_analysis': {},\n",
    "        'trend_analysis': {},\n",
    "        'hypothesis_testing': {},\n",
    "        'predictive_modeling': {},\n",
    "        'policy_recommendations': []\n",
    "    }\n",
    "\n",
    "   \n",
    "    if 'rainfall_mm' in df.columns:\n",
    "        insights['basic_statistics']['rainfall'] = {\n",
    "            'mean': float(df['rainfall_mm'].mean()),\n",
    "            'median': float(df['rainfall_mm'].median()),\n",
    "            'std': float(df['rainfall_mm'].std()),\n",
    "            'min': float(df['rainfall_mm'].min()),\n",
    "            'max': float(df['rainfall_mm'].max())\n",
    "        }\n",
    "\n",
    "    if 'avg_temp' in df.columns:\n",
    "        insights['basic_statistics']['temperature'] = {\n",
    "            'mean': float(df['avg_temp'].mean()),\n",
    "            'median': float(df['avg_temp'].median()),\n",
    "            'std': float(df['avg_temp'].std()),\n",
    "            'min': float(df['avg_temp'].min()),\n",
    "            'max': float(df['avg_temp'].max())\n",
    "        }\n",
    "\n",
    "   \n",
    "    if 'season' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        seasonal_rainfall = df.groupby('season')['rainfall_mm'].agg(['mean', 'std', 'count']).to_dict()\n",
    "        insights['seasonal_analysis'] = seasonal_rainfall\n",
    "\n",
    "    \n",
    "    if 'district' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        district_stats = df.groupby('district')['rainfall_mm'].agg(['mean', 'std', 'count']).to_dict()\n",
    "        insights['district_analysis'] = district_stats\n",
    "\n",
    "  \n",
    "    if 'risk_category' in df.columns:\n",
    "        risk_distribution = df['risk_category'].value_counts().to_dict()\n",
    "        insights['risk_analysis']['distribution'] = risk_distribution\n",
    "\n",
    "      \n",
    "        if 'district' in df.columns:\n",
    "            high_risk_districts = df[df['risk_category'] == 'High']['district'].value_counts().to_dict()\n",
    "            insights['risk_analysis']['high_risk_districts'] = high_risk_districts\n",
    "\n",
    "    \n",
    "    if 'year' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        yearly_trend = df.groupby('year')['rainfall_mm'].mean().to_dict()\n",
    "        insights['trend_analysis']['yearly_rainfall'] = yearly_trend\n",
    "\n",
    "   \n",
    "    insights['hypothesis_testing'] = perform_hypothesis_tests(df)\n",
    "\n",
    "    \n",
    "    insights['predictive_modeling'] = build_predictive_models(df)\n",
    "\n",
    "    \n",
    "    insights['policy_recommendations'] = generate_policy_recommendations(df)\n",
    "\n",
    "    \n",
    "    with open(f\"{Config.OUTPUT_DIR}/insights/comprehensive_insights.json\", 'w') as f:\n",
    "        json.dump(insights, f, indent=4, default=convert_numpy_types)\n",
    "\n",
    "   \n",
    "    generate_visualizations(df, insights)\n",
    "\n",
    "    logger.info(\"Insights generation complete\")\n",
    "    return insights\n",
    "\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"Convert numpy types to native Python types for JSON serialization\"\"\"\n",
    "    if isinstance(obj, (np.integer, np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.floating, np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, pd.Timestamp):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n",
    "\n",
    "def perform_hypothesis_tests(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"Perform statistical hypothesis tests\"\"\"\n",
    "    tests = {}\n",
    "\n",
    "    # Test 1: Is there a significant difference in rainfall between seasons?\n",
    "    if 'season' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        seasons = df['season'].unique()\n",
    "        if len(seasons) >= 2:\n",
    "            groups = [df[df['season'] == season]['rainfall_mm'].dropna() for season in seasons]\n",
    "            if all(len(group) > 1 for group in groups):\n",
    "                try:\n",
    "                    f_stat, p_value = stats.f_oneway(*groups)\n",
    "                    tests['seasonal_rainfall_anova'] = {\n",
    "                        'f_statistic': float(f_stat),\n",
    "                        'p_value': float(p_value),\n",
    "                        'significance': bool(p_value < 0.05),\n",
    "                        'interpretation': 'Significant difference between seasons' if p_value < 0.05 else 'No significant difference'\n",
    "                    }\n",
    "                except:\n",
    "                    tests['seasonal_rainfall_anova'] = {'error': 'Could not perform ANOVA test'}\n",
    "\n",
    "\n",
    "    if 'avg_temp' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        try:\n",
    "            valid_data = df[['avg_temp', 'rainfall_mm']].dropna()\n",
    "            if len(valid_data) > 2:\n",
    "                corr, p_value = stats.pearsonr(valid_data['avg_temp'], valid_data['rainfall_mm'])\n",
    "                tests['temperature_rainfall_correlation'] = {\n",
    "                    'correlation': float(corr),\n",
    "                    'p_value': float(p_value),\n",
    "                    'significance': bool(p_value < 0.05),\n",
    "                    'interpretation': 'Significant correlation' if p_value < 0.05 else 'No significant correlation'\n",
    "                }\n",
    "        except:\n",
    "            tests['temperature_rainfall_correlation'] = {'error': 'Could not calculate correlation'}\n",
    "\n",
    "    return tests\n",
    "\n",
    "def build_predictive_models(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"Build predictive models for rainfall and risk forecasting\"\"\"\n",
    "    modeling_results = {}\n",
    "    \n",
    "   \n",
    "    if all(col in df.columns for col in ['rainfall_mm', 'avg_temp', 'avg_humidity', 'district']):\n",
    "        try:\n",
    "            \n",
    "            model_df = df[['rainfall_mm', 'avg_temp', 'avg_humidity', 'district', 'month', 'year']].dropna()\n",
    "            \n",
    "           \n",
    "            le = LabelEncoder()\n",
    "            model_df['district_encoded'] = le.fit_transform(model_df['district'])\n",
    "            \n",
    "           \n",
    "            X = model_df[['avg_temp', 'avg_humidity', 'district_encoded', 'month', 'year']]\n",
    "            y = model_df['rainfall_mm']\n",
    "            \n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, shuffle=False\n",
    "            )\n",
    "            \n",
    "            \n",
    "            model = RandomForestRegressor(**Config.MODEL_PARAMS)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "           \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "           \n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "           \n",
    "            joblib.dump(model, f\"{Config.OUTPUT_DIR}/models/rainfall_predictor.pkl\")\n",
    "            \n",
    "            modeling_results['rainfall_prediction'] = {\n",
    "                'model_type': 'RandomForestRegressor',\n",
    "                'test_size': len(X_test),\n",
    "                'metrics': {\n",
    "                    'mse': float(mse),\n",
    "                    'rmse': float(rmse),\n",
    "                    'mae': float(mae),\n",
    "                    'r2': float(r2)\n",
    "                },\n",
    "                'feature_importance': {col: float(imp) for col, imp in zip(X.columns, model.feature_importances_)}\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error building rainfall prediction model: {str(e)}\")\n",
    "            modeling_results['rainfall_prediction'] = {'error': str(e)}\n",
    "    \n",
    "    \n",
    "    if all(col in df.columns for col in ['risk_category', 'avg_temp', 'rainfall_mm', 'district']):\n",
    "        try:\n",
    "           \n",
    "            risk_df = df[['risk_category', 'avg_temp', 'rainfall_mm', 'district', 'month']].dropna()\n",
    "            \n",
    "            \n",
    "            le_district = LabelEncoder()\n",
    "            le_risk = LabelEncoder()\n",
    "            risk_df['district_encoded'] = le_district.fit_transform(risk_df['district'])\n",
    "            risk_df['risk_encoded'] = le_risk.fit_transform(risk_df['risk_category'])\n",
    "            \n",
    "            \n",
    "            X = risk_df[['avg_temp', 'rainfall_mm', 'district_encoded', 'month']]\n",
    "            y = risk_df['risk_encoded']\n",
    "            \n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            \n",
    "            model = RandomForestClassifier(**Config.MODEL_PARAMS)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            \n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            \n",
    "          \n",
    "            joblib.dump(model, f\"{Config.OUTPUT_DIR}/models/risk_classifier.pkl\")\n",
    "            joblib.dump(le_risk, f\"{Config.OUTPUT_DIR}/models/risk_label_encoder.pkl\")\n",
    "            \n",
    "            modeling_results['risk_classification'] = {\n",
    "                'model_type': 'RandomForestClassifier',\n",
    "                'test_size': len(X_test),\n",
    "                'accuracy': float(accuracy),\n",
    "                'class_report': class_report\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error building risk classification model: {str(e)}\")\n",
    "            modeling_results['risk_classification'] = {'error': str(e)}\n",
    "    \n",
    "    return modeling_results\n",
    "\n",
    "def generate_policy_recommendations(df: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Generate policy recommendations based on data insights\"\"\"\n",
    "    recommendations = []\n",
    "\n",
    "   \n",
    "    if 'district' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        district_avg = df.groupby('district')['rainfall_mm'].mean()\n",
    "        overall_avg = df['rainfall_mm'].mean()\n",
    "\n",
    "        deficit_districts = district_avg[district_avg < overall_avg * 0.8]\n",
    "        for district, rainfall in deficit_districts.items():\n",
    "            deficit_pct = (1 - rainfall/overall_avg) * 100\n",
    "            recommendations.append({\n",
    "                'district': district,\n",
    "                'issue': f'{deficit_pct:.1f}% rainfall deficit',\n",
    "                'recommendation': 'Implement water conservation measures and drought-resistant crops',\n",
    "                'priority': 'High' if deficit_pct > 30 else 'Medium'\n",
    "            })\n",
    "\n",
    "   \n",
    "    if 'risk_category' in df.columns and 'district' in df.columns:\n",
    "        high_risk_districts = df[df['risk_category'] == 'High']['district'].value_counts()\n",
    "        for district, count in high_risk_districts.items():\n",
    "            recommendations.append({\n",
    "                'district': district,\n",
    "                'issue': f'{count} high-risk days detected',\n",
    "                'recommendation': 'Activate emergency response plan and increase monitoring',\n",
    "                'priority': 'High'\n",
    "            })\n",
    "            \n",
    "   \n",
    "    if 'heatwave_flag' in df.columns and 'district' in df.columns:\n",
    "        heatwave_districts = df[df['heatwave_flag'] == 1]['district'].value_counts()\n",
    "        for district, count in heatwave_districts.items():\n",
    "            if count > 10:  # Only if significant number of heatwave days\n",
    "                recommendations.append({\n",
    "                    'district': district,\n",
    "                    'issue': f'{count} heatwave days detected',\n",
    "                    'recommendation': 'Implement heat stress management for crops and livestock',\n",
    "                    'priority': 'Medium'\n",
    "                })\n",
    "                \n",
    "   \n",
    "    if 'dry_spell_length' in df.columns and 'district' in df.columns:\n",
    "        dry_spell_stats = df.groupby('district')['dry_spell_length'].max()\n",
    "        for district, max_dry_spell in dry_spell_stats.items():\n",
    "            if max_dry_spell > 30:  # More than 30 days dry spell\n",
    "                recommendations.append({\n",
    "                    'district': district,\n",
    "                    'issue': f'Extended dry spell of {max_dry_spell} days',\n",
    "                    'recommendation': 'Develop irrigation infrastructure and water storage',\n",
    "                    'priority': 'High'\n",
    "                })\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "def generate_visualizations(df: pd.DataFrame, insights: Dict[str, Any]):\n",
    "    \"\"\"Generate comprehensive visualizations\"\"\"\n",
    "    logger.info(\"Generating visualizations...\")\n",
    "\n",
    "    \n",
    "    if 'district' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        district_rain = df.groupby('district')['rainfall_mm'].mean().sort_values(ascending=False)\n",
    "        district_rain.plot(kind='bar')\n",
    "        plt.title('Average Rainfall by District')\n",
    "        plt.ylabel('Rainfall (mm)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/district_rainfall.png\")\n",
    "        plt.close()\n",
    "\n",
    "   \n",
    "    if 'season' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        seasonal_rain = df.groupby('season')['rainfall_mm'].mean()\n",
    "        seasonal_rain.plot(kind='bar')\n",
    "        plt.title('Average Rainfall by Season')\n",
    "        plt.ylabel('Rainfall (mm)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/seasonal_rainfall.png\")\n",
    "        plt.close()\n",
    "\n",
    "    \n",
    "    if 'risk_category' in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        risk_counts = df['risk_category'].value_counts()\n",
    "        risk_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "        plt.title('Distribution of Risk Categories')\n",
    "        plt.ylabel('')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/risk_distribution.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    if 'date' in df.columns and 'rainfall_mm' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        monthly_rain = df.set_index('date')['rainfall_mm'].resample('M').mean()\n",
    "        monthly_rain.plot()\n",
    "        plt.title('Monthly Average Rainfall Over Time')\n",
    "        plt.ylabel('Rainfall (mm)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/rainfall_timeseries.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    \n",
    "    if 'district' in df.columns and 'ari_normalized' in df.columns:\n",
    "        district_risk = df.groupby('district')['ari_normalized'].mean().reset_index()\n",
    "        \n",
    "        # Create a simple geocoding mapping for Telangana districts\n",
    "        district_coords = {\n",
    "            'Adilabad': (19.6667, 78.5333),\n",
    "            'Bhadradri': (17.6667, 80.6667),\n",
    "            'Hyderabad': (17.3850, 78.4867),\n",
    "            'Jagtial': (18.8000, 78.9333),\n",
    "            'Jangaon': (17.7200, 79.1800),\n",
    "            'Jayashankar': (18.8500, 79.9333),\n",
    "            'Jogulamba': (16.5000, 78.5000),\n",
    "            'Kamareddy': (18.3200, 78.3500),\n",
    "            'Karimnagar': (18.4333, 79.1500),\n",
    "            'Khammam': (17.2500, 80.1500),\n",
    "            'Komaram': (19.0500, 79.4667),\n",
    "            'Mahabubabad': (17.6000, 80.0167),\n",
    "            'Mahabubnagar': (16.7333, 77.9833),\n",
    "            'Mancherial': (18.8667, 79.4333),\n",
    "            'Medak': (18.0333, 78.2667),\n",
    "            'Medchal': (17.6300, 78.5000),\n",
    "            'Mulugu': (18.5333, 79.6667),\n",
    "            'Nagarkurnool': (16.4833, 78.3167),\n",
    "            'Nalgonda': (17.0500, 79.2667),\n",
    "            'Narayanpet': (16.7500, 77.5000),\n",
    "            'Nirmal': (19.1000, 78.3500),\n",
    "            'Nizamabad': (18.6700, 78.1000),\n",
    "            'Peddapalli': (18.6167, 79.3667),\n",
    "            'Rajanna': (18.3833, 78.8333),\n",
    "            'Rangareddy': (17.4000, 78.5000),\n",
    "            'Sangareddy': (17.6300, 78.1000),\n",
    "            'Siddipet': (18.1000, 78.8500),\n",
    "            'Suryapet': (17.1500, 79.6167),\n",
    "            'Vikarabad': (17.3300, 77.9000),\n",
    "            'Wanaparthy': (16.3667, 78.0667),\n",
    "            'Warangal': (17.9756, 79.6011),\n",
    "            'Yadadri': (17.6000, 78.9500)\n",
    "        }\n",
    "        \n",
    "        district_risk['lat'] = district_risk['district'].map(lambda x: district_coords.get(x, (0, 0))[0])\n",
    "        district_risk['lon'] = district_risk['district'].map(lambda x: district_coords.get(x, (0, 0))[1])\n",
    "        \n",
    "       \n",
    "        district_risk = district_risk[district_risk['lat'] != 0]\n",
    "        \n",
    "        if len(district_risk) > 0:\n",
    "            fig = px.scatter_mapbox(\n",
    "                district_risk, \n",
    "                lat=\"lat\", \n",
    "                lon=\"lon\", \n",
    "                hover_name=\"district\", \n",
    "                size=\"ari_normalized\",\n",
    "                color=\"ari_normalized\",\n",
    "                color_continuous_scale=px.colors.sequential.Redor,\n",
    "                size_max=30,\n",
    "                zoom=6,\n",
    "                title=\"Agricultural Risk Index by District\"\n",
    "            )\n",
    "            \n",
    "            fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "            fig.update_layout(margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "            fig.write_html(f\"{Config.OUTPUT_DIR}/visualizations/risk_map.html\")\n",
    "\n",
    "    logger.info(\"Visualizations generated\")\n",
    "\n",
    "print(\"Insights generation functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de714db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI interface and cross-sector analysis functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class RTGSCLI:\n",
    "    \"\"\"CLI interface for the RTGS system\"\"\"\n",
    "    \n",
    "    def __init__(self, df, insights):\n",
    "        self.df = df\n",
    "        self.insights = insights\n",
    "        self.saved_queries = {}\n",
    "        self.filter_state = Config.INTERACTIVE_FILTERS.copy()\n",
    "    \n",
    "    def show_summary(self):\n",
    "        \"\"\"Show summary of the analysis\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"TELANGANA AGRI-WEATHER RTGS SYSTEM - ANALYSIS SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Data Period: {self.df['date'].min().strftime('%Y-%m-%d')} to {self.df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Districts Analyzed: {self.df['district'].nunique()}\")\n",
    "        print(f\"Total Records: {len(self.df):,}\")\n",
    "        if 'high_risk_districts' in self.insights['risk_analysis']:\n",
    "            print(f\"High-Risk Districts: {len(self.insights['risk_analysis']['high_risk_districts'])}\")\n",
    "        print()\n",
    "        \n",
    "     \n",
    "        if 'rainfall_mm' in self.df.columns:\n",
    "            print(f\"Average Rainfall: {self.df['rainfall_mm'].mean():.1f} mm\")\n",
    "            print(f\"Max Rainfall: {self.df['rainfall_mm'].max():.1f} mm\")\n",
    "            print(f\"Min Rainfall: {self.df['rainfall_mm'].min():.1f} mm\")\n",
    "        print()\n",
    "    \n",
    "    def show_high_risk_districts(self, top_n=10):\n",
    "        \"\"\"Show districts with highest risk\"\"\"\n",
    "        if 'high_risk_districts' in self.insights['risk_analysis']:\n",
    "            print(\"DISTRICTS WITH HIGHEST RISK:\")\n",
    "            print(\"-\" * 40)\n",
    "            high_risk = self.insights['risk_analysis']['high_risk_districts']\n",
    "            for i, (district, count) in enumerate(list(high_risk.items())[:top_n]):\n",
    "                print(f\"{i+1}. {district}: {count} high-risk days\")\n",
    "            print()\n",
    "        else:\n",
    "            print(\"No high-risk districts data available.\")\n",
    "    \n",
    "    def show_policy_recommendations(self, top_n=5):\n",
    "        \"\"\"Show top policy recommendations\"\"\"\n",
    "        if self.insights['policy_recommendations']:\n",
    "            print(\"TOP POLICY RECOMENDATIONS:\")\n",
    "            print(\"-\" * 40)\n",
    "            for i, rec in enumerate(self.insights['policy_recommendations'][:top_n]):\n",
    "                print(f\"{i+1}. {rec['district']}: {rec['issue']}\")\n",
    "                print(f\"   Recommendation: {rec['recommendation']}\")\n",
    "                print(f\"   Priority: {rec['priority']}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"No policy recommendations available.\")\n",
    "    \n",
    "    def run_hypothesis_test(self, test_name):\n",
    "        \"\"\"Run specific hypothesis test\"\"\"\n",
    "        if test_name in self.insights['hypothesis_testing']:\n",
    "            test = self.insights['hypothesis_testing'][test_name]\n",
    "            print(f\"HYPOTHESIS TEST: {test_name.upper()}\")\n",
    "            print(\"-\" * 40)\n",
    "            for key, value in test.items():\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"Test '{test_name}' not found. Available tests: {list(self.insights['hypothesis_testing'].keys())}\")\n",
    "    \n",
    "    def show_model_performance(self):\n",
    "        \"\"\"Show predictive model performance\"\"\"\n",
    "        if 'predictive_modeling' in self.insights:\n",
    "            print(\"PREDICTIVE MODEL PERFORMANCE:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            if 'rainfall_prediction' in self.insights['predictive_modeling']:\n",
    "                rainfall_model = self.insights['predictive_modeling']['rainfall_prediction']\n",
    "                if 'error' not in rainfall_model:\n",
    "                    print(\"Rainfall Prediction Model:\")\n",
    "                    print(f\"  RMSE: {rainfall_model['metrics']['rmse']:.2f}\")\n",
    "                    print(f\"  R² Score: {rainfall_model['metrics']['r2']:.3f}\")\n",
    "                    print(\"  Feature Importance:\")\n",
    "                    for feature, importance in rainfall_model['feature_importance'].items():\n",
    "                        print(f\"    {feature}: {importance:.3f}\")\n",
    "                    print()\n",
    "            \n",
    "            if 'risk_classification' in self.insights['predictive_modeling']:\n",
    "                risk_model = self.insights['predictive_modeling']['risk_classification']\n",
    "                if 'error' not in risk_model:\n",
    "                    print(\"Risk Classification Model:\")\n",
    "                    print(f\"  Accuracy: {risk_model['accuracy']:.3f}\")\n",
    "                    print()\n",
    "        else:\n",
    "            print(\"No predictive modeling results available.\")\n",
    "    \n",
    "    def export_results(self, format='csv'):\n",
    "        \"\"\"Export results to various formats with Excel size limitations handling\"\"\"\n",
    "        if format == 'csv':\n",
    "            \n",
    "            try:\n",
    "               \n",
    "                self.df.to_csv(f\"{Config.OUTPUT_DIR}/exports/full_dataset.csv\", index=False)\n",
    "                \n",
    "           \n",
    "                if self.insights['policy_recommendations']:\n",
    "                    pd.DataFrame(self.insights['policy_recommendations']).to_csv(\n",
    "                        f\"{Config.OUTPUT_DIR}/exports/policy_recommendations.csv\", index=False\n",
    "                    )\n",
    "                print(f\"✅ Results exported to CSV format in {Config.OUTPUT_DIR}/exports/\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ CSV export error: {str(e)}\")\n",
    "                print(\"🔄 Trying alternative export methods...\")\n",
    "                self.export_large_data()\n",
    "                \n",
    "        elif format == 'excel':\n",
    "            try:\n",
    "             \n",
    "                if len(self.df) > 1048576 or len(self.df.columns) > 16384:\n",
    "                    print(\"⚠️ Dataset exceeds Excel limits. Exporting sample data instead.\")\n",
    "                    \n",
    "                   \n",
    "                    sample_size = min(100000, len(self.df) // 100)\n",
    "                    sample_df = self.df.sample(n=sample_size, random_state=42)\n",
    "                    \n",
    "                    with pd.ExcelWriter(f\"{Config.OUTPUT_DIR}/exports/rtgs_analysis_sample.xlsx\", engine='openpyxl') as writer:\n",
    "                        \n",
    "                        sample_df.to_excel(writer, sheet_name='Sample Data', index=False)\n",
    "                        \n",
    "                        if self.insights['policy_recommendations']:\n",
    "                            pd.DataFrame(self.insights['policy_recommendations']).to_excel(\n",
    "                                writer, sheet_name='Policy Recommendations', index=False\n",
    "                            )\n",
    "                        \n",
    "                        \n",
    "                        summary_data = {\n",
    "                            'Metric': ['Start Date', 'End Date', 'Districts', 'Total Records', 'Sample Size'],\n",
    "                            'Value': [\n",
    "                                self.df['date'].min().strftime('%Y-%m-%d'),\n",
    "                                self.df['date'].max().strftime('%Y-%m-%d'),\n",
    "                                self.df['district'].nunique(),\n",
    "                                len(self.df),\n",
    "                                len(sample_df)\n",
    "                            ]\n",
    "                        }\n",
    "                        \n",
    "                        \n",
    "                        if 'high_risk_districts' in self.insights['risk_analysis']:\n",
    "                            summary_data['Metric'].append('High Risk Districts')\n",
    "                            summary_data['Value'].append(len(self.insights['risk_analysis']['high_risk_districts']))\n",
    "                        \n",
    "                        pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n",
    "                        \n",
    "                        \n",
    "                        for sheet_name in writer.sheets:\n",
    "                            worksheet = writer.sheets[sheet_name]\n",
    "                            if hasattr(worksheet, 'sheet_state') and worksheet.sheet_state == 'hidden':\n",
    "                                worksheet.sheet_state = 'visible'\n",
    "                    \n",
    "                    print(f\"✅ Sample data exported to Excel format in {Config.OUTPUT_DIR}/exports/\")\n",
    "                    print(\"💡 Note: Full dataset exceeds Excel limits. Use CSV format for complete data.\")\n",
    "                    \n",
    "                    # Also export the full data to CSV\n",
    "                    self.export_results('csv')\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    with pd.ExcelWriter(f\"{Config.OUTPUT_DIR}/exports/rtgs_analysis.xlsx\", engine='openpyxl') as writer:\n",
    "                        self.df.to_excel(writer, sheet_name='Full Data', index=False)\n",
    "                        \n",
    "                        if self.insights['policy_recommendations']:\n",
    "                            pd.DataFrame(self.insights['policy_recommendations']).to_excel(\n",
    "                                writer, sheet_name='Policy Recommendations', index=False\n",
    "                            )\n",
    "                        \n",
    "                        \n",
    "                        summary_data = {\n",
    "                            'Metric': ['Start Date', 'End Date', 'Districts', 'Total Records'],\n",
    "                            'Value': [\n",
    "                                self.df['date'].min().strftime('%Y-%m-%d'),\n",
    "                                self.df['date'].max().strftime('%Y-%m-%d'),\n",
    "                                self.df['district'].nunique(),\n",
    "                                len(self.df),\n",
    "                            ]\n",
    "                        }\n",
    "                        \n",
    "                        \n",
    "                        if 'high_risk_districts' in self.insights['risk_analysis']:\n",
    "                            summary_data['Metric'].append('High Risk Districts')\n",
    "                            summary_data['Value'].append(len(self.insights['risk_analysis']['high_risk_districts']))\n",
    "                        \n",
    "                        pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)\n",
    "                        \n",
    "                     \n",
    "                        for sheet_name in writer.sheets:\n",
    "                            worksheet = writer.sheets[sheet_name]\n",
    "                            if hasattr(worksheet, 'sheet_state') and worksheet.sheet_state == 'hidden':\n",
    "                                worksheet.sheet_state = 'visible'\n",
    "                    \n",
    "                    print(f\"✅ Results exported to Excel format in {Config.OUTPUT_DIR}/exports/\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Excel export error: {str(e)}\")\n",
    "                print(\"🔄 Falling back to CSV export...\")\n",
    "                self.export_results('csv')\n",
    "        else:\n",
    "            print(\"❌ Supported formats: csv, excel\")\n",
    "\n",
    "    def export_large_data(self):\n",
    "        \"\"\"Export large datasets that exceed Excel limits by splitting into manageable chunks\"\"\"\n",
    "        print(\"📦 Exporting large dataset in chunks...\")\n",
    "        \n",
    "        try:\n",
    "            # Split data by year if available\n",
    "            if 'year' in self.df.columns:\n",
    "                years = sorted(self.df['year'].unique())\n",
    "                for year in years:\n",
    "                    year_data = self.df[self.df['year'] == year]\n",
    "                    if len(year_data) > 0:\n",
    "                        year_data.to_csv(\n",
    "                            f\"{Config.OUTPUT_DIR}/exports/full_dataset_{int(year)}.csv\", \n",
    "                            index=False\n",
    "                        )\n",
    "                        print(f\"✅ Exported {len(year_data)} records for year {year}\")\n",
    "                print(f\"✅ Data exported by year to {Config.OUTPUT_DIR}/exports/\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                chunk_size = 500000 \n",
    "                num_chunks = (len(self.df) // chunk_size) + 1\n",
    "                \n",
    "                for i in range(num_chunks):\n",
    "                    start_idx = i * chunk_size\n",
    "                    end_idx = min((i + 1) * chunk_size, len(self.df))\n",
    "                    chunk_data = self.df.iloc[start_idx:end_idx]\n",
    "                    \n",
    "                    chunk_data.to_csv(\n",
    "                        f\"{Config.OUTPUT_DIR}/exports/full_dataset_part_{i+1}.csv\", \n",
    "                        index=False\n",
    "                    )\n",
    "                    print(f\"✅ Exported chunk {i+1}: {len(chunk_data)} records\")\n",
    "                    \n",
    "                print(f\"✅ Data exported in {num_chunks} chunks to {Config.OUTPUT_DIR}/exports/\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error exporting large data: {str(e)}\")\n",
    "            print(\"🔄 Trying alternative export method...\")\n",
    "            \n",
    "          \n",
    "            try:\n",
    "                sample_df = self.df.sample(n=min(100000, len(self.df)), random_state=42)\n",
    "                sample_df.to_csv(f\"{Config.OUTPUT_DIR}/exports/full_dataset_sample.csv\", index=False)\n",
    "                print(f\"✅ Exported sample of {len(sample_df)} records\")\n",
    "            except Exception as sample_error:\n",
    "                print(f\"❌ Failed to export sample: {str(sample_error)}\")\n",
    "    \n",
    "    def interactive_analysis(self):\n",
    "        \"\"\"Launch an interactive analysis session\"\"\"\n",
    "        print(\"Launching interactive analysis...\")\n",
    "        print(\"Available variables: df, insights\")\n",
    "        print(\"Type 'exit' to return to the main menu\")\n",
    "        \n",
    "        # Provide access to the dataframes\n",
    "        import code\n",
    "        variables = globals().copy()\n",
    "        variables.update(locals())\n",
    "        variables['df'] = self.df\n",
    "        variables['insights'] = self.insights\n",
    "        \n",
    "        shell = code.InteractiveConsole(variables)\n",
    "        shell.interact(banner=\"Interactive Analysis Session (Type 'exit()' to return)\")\n",
    "    \n",
    "    def create_interactive_dashboard(self):\n",
    "        \"\"\"Create an interactive dashboard with filters\"\"\"\n",
    "        print(\"Creating interactive dashboard...\")\n",
    "        \n",
    "       \n",
    "        district_options = ['All'] + sorted(self.df['district'].unique().tolist())\n",
    "        season_options = ['All'] + sorted(self.df['season'].unique().tolist()) if 'season' in self.df.columns else ['All']\n",
    "        \n",
    "      \n",
    "        risk_options = ['All']\n",
    "        if 'risk_category' in self.df.columns:\n",
    "            risk_options += sorted(self.df['risk_category'].unique().tolist())\n",
    "        \n",
    "        district_widget = widgets.Dropdown(\n",
    "            options=district_options,\n",
    "            value='All',\n",
    "            description='District:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "        season_widget = widgets.Dropdown(\n",
    "            options=season_options,\n",
    "            value='All',\n",
    "            description='Season:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "       \n",
    "        if 'year' in self.df.columns:\n",
    "            year_min = self.df['year'].min()\n",
    "            year_max = self.df['year'].max()\n",
    "            year_widget = widgets.IntRangeSlider(\n",
    "                value=[year_min, year_max],\n",
    "                min=year_min,\n",
    "                max=year_max,\n",
    "                step=1,\n",
    "                description='Year Range:',\n",
    "                disabled=False\n",
    "            )\n",
    "        else:\n",
    "            year_widget = widgets.IntRangeSlider(\n",
    "                value=[2010, 2023],\n",
    "                min=2010,\n",
    "                max=2023,\n",
    "                step=1,\n",
    "                description='Year Range:',\n",
    "                disabled=False\n",
    "            )\n",
    "        \n",
    "        risk_widget = widgets.Dropdown(\n",
    "            options=risk_options,\n",
    "            value='All',\n",
    "            description='Risk Level:',\n",
    "            disabled=False\n",
    "        )\n",
    "        \n",
    "      \n",
    "        @interact(\n",
    "            district=district_widget,\n",
    "            season=season_widget,\n",
    "            year_range=year_widget,\n",
    "            risk_level=risk_widget\n",
    "        )\n",
    "        def update_dashboard(district, season, year_range, risk_level):\n",
    "            # Filter data based on selections\n",
    "            filtered_df = self.df.copy()\n",
    "            \n",
    "            if district != 'All':\n",
    "                filtered_df = filtered_df[filtered_df['district'] == district]\n",
    "            \n",
    "            if season != 'All' and 'season' in filtered_df.columns:\n",
    "                filtered_df = filtered_df[filtered_df['season'] == season]\n",
    "            \n",
    "            if risk_level != 'All' and 'risk_category' in filtered_df.columns:\n",
    "                filtered_df = filtered_df[filtered_df['risk_category'] == risk_level]\n",
    "            \n",
    "            if 'year' in filtered_df.columns:\n",
    "                filtered_df = filtered_df[\n",
    "                    (filtered_df['year'] >= year_range[0]) & \n",
    "                    (filtered_df['year'] <= year_range[1])\n",
    "                ]\n",
    "            \n",
    "          \n",
    "            self.create_filtered_visualizations(filtered_df)\n",
    "            \n",
    "\n",
    "            self.filter_state = {\n",
    "                'district': district,\n",
    "                'season': season,\n",
    "                'year_range': year_range,\n",
    "                'risk_level': risk_level\n",
    "            }\n",
    "        \n",
    "     \n",
    "        self.filter_widgets = {\n",
    "            'district': district_widget,\n",
    "            'season': season_widget,\n",
    "            'year_range': year_widget,\n",
    "            'risk_level': risk_widget\n",
    "        }\n",
    "        \n",
    "        print(\"Interactive dashboard created. Use the filters above to explore the data.\")\n",
    "    \n",
    "    def create_filtered_visualizations(self, filtered_df):\n",
    "        \"\"\"Create visualizations based on filtered data\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "     \n",
    "        if 'month' in filtered_df.columns and 'rainfall_mm' in filtered_df.columns:\n",
    "            monthly_rain = filtered_df.groupby('month')['rainfall_mm'].mean()\n",
    "            axes[0, 0].bar(monthly_rain.index, monthly_rain.values)\n",
    "            axes[0, 0].set_title('Average Rainfall by Month')\n",
    "            axes[0, 0].set_xlabel('Month')\n",
    "            axes[0, 0].set_ylabel('Rainfall (mm)')\n",
    "        \n",
    "        \n",
    "        if 'risk_category' in filtered_df.columns:\n",
    "            risk_counts = filtered_df['risk_category'].value_counts()\n",
    "            axes[0, 1].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%')\n",
    "            axes[0, 1].set_title('Risk Category Distribution')\n",
    "        \n",
    "      \n",
    "        if 'avg_temp' in filtered_df.columns:\n",
    "            axes[1, 0].hist(filtered_df['avg_temp'].dropna(), bins=30, alpha=0.7)\n",
    "            axes[1, 0].set_title('Temperature Distribution')\n",
    "            axes[1, 0].set_xlabel('Temperature (°C)')\n",
    "            axes[1, 0].set_ylabel('Frequency')\n",
    "        \n",
    "       \n",
    "        if 'date' in filtered_df.columns and 'rainfall_mm' in filtered_df.columns:\n",
    "            time_series = filtered_df.set_index('date')['rainfall_mm'].resample('M').mean()\n",
    "            axes[1, 1].plot(time_series.index, time_series.values)\n",
    "            axes[1, 1].set_title('Monthly Rainfall Over Time')\n",
    "            axes[1, 1].set_xlabel('Date')\n",
    "            axes[1, 1].set_ylabel('Rainfall (mm)')\n",
    "            axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{Config.OUTPUT_DIR}/interactive/filtered_visualization.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "       \n",
    "        print(f\"Filtered Data Summary:\")\n",
    "        print(f\"Records: {len(filtered_df):,}\")\n",
    "        if 'date' in filtered_df.columns:\n",
    "            print(f\"Time Period: {filtered_df['date'].min().strftime('%Y-%m-%d')} to {filtered_df['date'].max().strftime('%Y-%m-%d')}\")\n",
    "        if 'rainfall_mm' in filtered_df.columns:\n",
    "            print(f\"Average Rainfall: {filtered_df['rainfall_mm'].mean():.1f} mm\")\n",
    "        if 'risk_category' in filtered_df.columns:\n",
    "            risk_dist = filtered_df['risk_category'].value_counts().to_dict()\n",
    "            print(\"Risk Distribution:\")\n",
    "            for risk, count in risk_dist.items():\n",
    "                print(f\"  {risk}: {count} records ({count/len(filtered_df)*100:.1f}%)\")\n",
    "    \n",
    "    def save_query(self, query_name, description=\"\"):\n",
    "        \"\"\"Save the current filter state as a query\"\"\"\n",
    "        self.saved_queries[query_name] = {\n",
    "            'filters': self.filter_state,\n",
    "            'description': description,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        \n",
    "        os.makedirs(f\"{Config.OUTPUT_DIR}/interactive\", exist_ok=True)\n",
    "        with open(f\"{Config.OUTPUT_DIR}/interactive/saved_queries.json\", 'w') as f:\n",
    "            json.dump(self.saved_queries, f, indent=4)\n",
    "        \n",
    "        print(f\"Query '{query_name}' saved successfully.\")\n",
    "    \n",
    "    def load_query(self, query_name):\n",
    "        \"\"\"Load a saved query and apply filters\"\"\"\n",
    "        if query_name in self.saved_queries:\n",
    "            filters = self.saved_queries[query_name]['filters']\n",
    "            \n",
    "            \n",
    "            for key, value in filters.items():\n",
    "                if key in self.filter_widgets:\n",
    "                    self.filter_widgets[key].value = value\n",
    "            \n",
    "            print(f\"Query '{query_name}' loaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Query '{query_name}' not found.\")\n",
    "    \n",
    "    def semantic_query(self, question):\n",
    "        \"\"\"Answer semantic questions about the data\"\"\"\n",
    "        question = question.lower()\n",
    "        \n",
    "        # Simple question-answering logic\n",
    "        if 'rainfall' in question and 'average' in question:\n",
    "            if 'district' in question:\n",
    "                # Find which district is mentioned\n",
    "                districts = self.df['district'].unique()\n",
    "                mentioned_district = None\n",
    "                for district in districts:\n",
    "                    if district.lower() in question:\n",
    "                        mentioned_district = district\n",
    "                        break\n",
    "                \n",
    "                if mentioned_district:\n",
    "                    avg_rainfall = self.df[self.df['district'] == mentioned_district]['rainfall_mm'].mean()\n",
    "                    return f\"The average rainfall in {mentioned_district} is {avg_rainfall:.1f} mm.\"\n",
    "                else:\n",
    "                    return \"I couldn't determine which district you're asking about. Please specify.\"\n",
    "            \n",
    "            else:\n",
    "                avg_rainfall = self.df['rainfall_mm'].mean()\n",
    "                return f\"The average rainfall across all districts is {avg_rainfall:.1f} mm.\"\n",
    "        \n",
    "        elif 'high risk' in question and 'district' in question:\n",
    "            if 'high_risk_districts' in self.insights['risk_analysis']:\n",
    "                high_risk_districts = self.insights['risk_analysis']['high_risk_districts']\n",
    "                if high_risk_districts:\n",
    "                    top_district = max(high_risk_districts, key=high_risk_districts.get)\n",
    "                    return f\"The district with the highest risk is {top_district} with {high_risk_districts[top_district]} high-risk days.\"\n",
    "                else:\n",
    "                    return \"No high-risk districts found in the data.\"\n",
    "            else:\n",
    "                return \"No high-risk districts data available.\"\n",
    "        \n",
    "        elif 'recommendation' in question or 'suggestion' in question:\n",
    "            if 'district' in question:\n",
    "                # Find which district is mentioned\n",
    "                districts = self.df['district'].unique()\n",
    "                mentioned_district = None\n",
    "                for district in districts:\n",
    "                    if district.lower() in question:\n",
    "                        mentioned_district = district\n",
    "                        break\n",
    "                \n",
    "                if mentioned_district:\n",
    "                    # Find recommendations for this district\n",
    "                    district_recs = [rec for rec in self.insights['policy_recommendations'] if rec['district'] == mentioned_district]\n",
    "                    if district_recs:\n",
    "                        response = f\"Recommendations for {mentioned_district}:\\n\"\n",
    "                        for i, rec in enumerate(district_recs[:3]):  # Top 3 recommendations\n",
    "                            response += f\"{i+1}. {rec['recommendation']} (Priority: {rec['priority']})\\n\"\n",
    "                        return response\n",
    "                    else:\n",
    "                        return f\"No specific recommendations found for {mentioned_district}.\"\n",
    "                else:\n",
    "                    return \"I couldn't determine which district you're asking about. Please specify.\"\n",
    "            \n",
    "            else:\n",
    "                # Return general recommendations\n",
    "                if self.insights['policy_recommendations']:\n",
    "                    response = \"Top recommendations:\\n\"\n",
    "                    for i, rec in enumerate(self.insights['policy_recommendations'][:3]):  # Top 3 recommendations\n",
    "                        response += f\"{i+1}. For {rec['district']}: {rec['recommendation']} (Priority: {rec['priority']})\\n\"\n",
    "                    return response\n",
    "                else:\n",
    "                    return \"No recommendations available.\"\n",
    "        \n",
    "        else:\n",
    "            return \"I'm not sure how to answer that question. Try asking about rainfall, high-risk districts, or recommendations.\"\n",
    "\n",
    "def convert_keys_to_serializable(obj):\n",
    "    \"\"\"\n",
    "    Recursively convert non-JSON-serializable keys to serializable formats\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        new_dict = {}\n",
    "        for key, value in obj.items():\n",
    "            # Convert tuple keys to strings\n",
    "            if isinstance(key, tuple):\n",
    "                # Convert tuple to string representation\n",
    "                new_key = str(key)\n",
    "            elif isinstance(key, (int, float, bool)) or key is None:\n",
    "                # These are JSON-serializable as keys\n",
    "                new_key = key\n",
    "            else:\n",
    "                # Ensure other key types are strings\n",
    "                new_key = str(key)\n",
    "            \n",
    "            # Recursively process values\n",
    "            new_dict[new_key] = convert_keys_to_serializable(value)\n",
    "        return new_dict\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_keys_to_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        # Convert tuples to lists for JSON serialization\n",
    "        return [convert_keys_to_serializable(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def perform_cross_sector_analysis(df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"Perform cross-sector analysis joining different data aspects\"\"\"\n",
    "    logger.info(\"Performing cross-sector analysis...\")\n",
    "    \n",
    "    analysis_results = {}\n",
    "    \n",
    "   \n",
    "    if all(col in df.columns for col in ['rainfall_mm', 'avg_temp', 'risk_category']):\n",
    "        # Only include numerical columns in aggregation\n",
    "        agg_dict = {\n",
    "            'rainfall_mm': ['mean', 'std', 'count'],\n",
    "            'avg_temp': ['mean', 'std'],\n",
    "        }\n",
    "        \n",
    "      \n",
    "        if 'avg_humidity' in df.columns:\n",
    "            agg_dict['avg_humidity'] = ['mean', 'std']\n",
    "            \n",
    "        weather_by_risk = df.groupby('risk_category').agg(agg_dict)\n",
    "        \n",
    "    \n",
    "        analysis_results['weather_by_risk'] = weather_by_risk.to_dict()\n",
    "    \n",
    " \n",
    "    if all(col in df.columns for col in ['date', 'risk_category']):\n",
    "        risk_over_time = (\n",
    "            df.groupby(['risk_category', pd.Grouper(key='date', freq='M')])\n",
    "              .size()\n",
    "              .unstack(fill_value=0)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        risk_over_time.columns = risk_over_time.columns.strftime(\"%Y-%m\")\n",
    "        \n",
    "        analysis_results['risk_trends'] = risk_over_time.to_dict()\n",
    "    \n",
    "  \n",
    "    if all(col in df.columns for col in ['district', 'risk_category']):\n",
    "        district_risk = df.groupby(['district', 'risk_category']).size().unstack(fill_value=0)\n",
    "        district_risk['total_days'] = district_risk.sum(axis=1)\n",
    "        \n",
    "       \n",
    "        if 'High' in district_risk.columns:\n",
    "            district_risk['high_risk_ratio'] = district_risk['High'] / district_risk['total_days']\n",
    "        \n",
    "        analysis_results['district_risk_profiles'] = district_risk.to_dict()\n",
    "    \n",
    "\n",
    "    if all(col in df.columns for col in ['risk_category', 'district']):\n",
    "        # Check if risk_category is categorical\n",
    "        if not pd.api.types.is_categorical_dtype(df['risk_category']):\n",
    "            # Simplified economic impact model\n",
    "            risk_impact_factors = {\n",
    "                'Low': 0.1,\n",
    "                'Medium': 0.5,\n",
    "                'High': 0.9\n",
    "            }\n",
    "            \n",
    "            df['impact_factor'] = df['risk_category'].map(risk_impact_factors)\n",
    "            \n",
    "            # District-wise economic impact (simplified)\n",
    "            district_impact = df.groupby('district').agg({\n",
    "                'impact_factor': 'mean',\n",
    "                'risk_category': 'count'\n",
    "            }).rename(columns={'risk_category': 'total_days'})\n",
    "            \n",
    "            district_impact['relative_impact'] = district_impact['impact_factor'] / district_impact['impact_factor'].max()\n",
    "            \n",
    "            analysis_results['economic_impact'] = district_impact.to_dict()\n",
    "    \n",
    "    \n",
    "    serializable_results = convert_keys_to_serializable(analysis_results)\n",
    "    \n",
    "  \n",
    "    os.makedirs(f\"{Config.OUTPUT_DIR}/insights\", exist_ok=True)\n",
    "    with open(f\"{Config.OUTPUT_DIR}/insights/cross_sector_analysis.json\", 'w') as f:\n",
    "        json.dump(serializable_results, f, indent=4)\n",
    "    \n",
    "    logger.info(\"Cross-sector analysis complete\")\n",
    "    return analysis_results\n",
    "\n",
    "def create_comprehensive_report():\n",
    "    \"\"\"Create a comprehensive PDF report of all findings\"\"\"\n",
    "    try:\n",
    "        from fpdf import FPDF\n",
    "        import matplotlib.pyplot as plt\n",
    "        from datetime import datetime\n",
    "        \n",
    "        \n",
    "        pdf = FPDF()\n",
    "        pdf.set_auto_page_break(auto=True, margin=15)\n",
    "        pdf.add_page()\n",
    "        \n",
    "        \n",
    "        pdf.set_font('Arial', 'B', 16)\n",
    "        pdf.cell(0, 10, 'TELANGANA AGRI-WEATHER RTGS SYSTEM - COMPREHENSIVE REPORT', 0, 1, 'C')\n",
    "        pdf.ln(5)\n",
    "        \n",
    "     \n",
    "        pdf.set_font('Arial', '', 12)\n",
    "        pdf.cell(0, 10, f'Report generated on: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}', 0, 1, 'C')\n",
    "        pdf.ln(10)\n",
    "        \n",
    "      \n",
    "        insights_path = f\"{Config.OUTPUT_DIR}/insights/comprehensive_insights.json\"\n",
    "        if os.path.exists(insights_path):\n",
    "            with open(insights_path, 'r') as f:\n",
    "                insights = json.load(f)\n",
    "        else:\n",
    "            insights = {}\n",
    "        \n",
    "        \n",
    "        pdf.set_font('Arial', 'B', 14)\n",
    "        pdf.cell(0, 10, 'Executive Summary', 0, 1)\n",
    "        pdf.set_font('Arial', '', 12)\n",
    "        \n",
    "      \n",
    "        try:\n",
    "            df_path = f\"{Config.OUTPUT_DIR}/cleaned/data_cleaned.parquet\"\n",
    "            if os.path.exists(df_path):\n",
    "                df_clean = pd.read_parquet(df_path)\n",
    "                total_records = len(df_clean)\n",
    "                districts = df_clean['district'].nunique()\n",
    "            else:\n",
    "                total_records = \"N/A\"\n",
    "                districts = \"N/A\"\n",
    "        except:\n",
    "            total_records = \"N/A\"\n",
    "            districts = \"N/A\"\n",
    "            \n",
    "        high_risk_districts = len(insights.get('risk_analysis', {}).get('high_risk_districts', {}))\n",
    "        \n",
    "        summary_text = f\"\"\"\n",
    "        This report presents a comprehensive analysis of agricultural weather risks across Telangana.\n",
    "        The analysis covers {districts} districts with a total of {total_records:,} data points.\n",
    "        \n",
    "        Key findings:\n",
    "        - Average rainfall: {insights.get('basic_statistics', {}).get('rainfall', {}).get('mean', 'N/A'):.1f} mm\n",
    "        - High-risk districts identified: {high_risk_districts}\n",
    "        - {len(insights.get('policy_recommendations', []))} policy recommendations generated\n",
    "        \"\"\"\n",
    "        \n",
    "        pdf.multi_cell(0, 8, summary_text)\n",
    "        pdf.ln(10)\n",
    "        \n",
    "        \n",
    "        pdf.set_font('Arial', 'B', 14)\n",
    "        pdf.cell(0, 10, 'Risk Analysis', 0, 1)\n",
    "        pdf.set_font('Arial', '', 12)\n",
    "        \n",
    "       \n",
    "        risk_img = f\"{Config.OUTPUT_DIR}/visualizations/risk_distribution.png\"\n",
    "        if os.path.exists(risk_img):\n",
    "            pdf.image(risk_img, x=10, y=None, w=180)\n",
    "            pdf.ln(80)  # Adjust based on image height\n",
    "        \n",
    "      \n",
    "        pdf.set_font('Arial', 'B', 14)\n",
    "        pdf.cell(0, 10, 'Policy Recommendations', 0, 1)\n",
    "        pdf.set_font('Arial', '', 12)\n",
    "        \n",
    "        for i, rec in enumerate(insights.get('policy_recommendations', [])[:5]):\n",
    "            pdf.cell(0, 8, f\"{i+1}. {rec.get('district', 'Unknown')}: {rec.get('issue', 'No issue specified')}\", 0, 1)\n",
    "            pdf.cell(0, 8, f\"   Recommendation: {rec.get('recommendation', 'No recommendation')}\", 0, 1)\n",
    "            pdf.cell(0, 8, f\"   Priority: {rec.get('priority', 'Unknown')}\", 0, 1)\n",
    "            pdf.ln(2)\n",
    "        \n",
    "       \n",
    "        os.makedirs(f\"{Config.OUTPUT_DIR}/reports\", exist_ok=True)\n",
    "        pdf_path = f\"{Config.OUTPUT_DIR}/reports/comprehensive_analysis_report.pdf\"\n",
    "        pdf.output(pdf_path)\n",
    "        \n",
    "        logger.info(f\"Comprehensive report generated: {pdf_path}\")\n",
    "        return pdf_path\n",
    "        \n",
    "    except ImportError:\n",
    "        logger.warning(\"fpdf not installed. Skipping PDF report generation.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating PDF report: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"CLI interface and cross-sector analysis functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d889395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main execution function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Main execution function\n",
    "def run_rtgs_pipeline(data_path=None):\n",
    "    \"\"\"Run the complete RTGS pipeline\"\"\"\n",
    "    start_time = datetime.now()\n",
    "    logger.info(\"Starting RTGS Pipeline\")\n",
    "    \n",
    "   \n",
    "    setup_directories()\n",
    "    \n",
    "    \n",
    "    if data_path is None:\n",
    "        data_path = Config.DATA_PATH\n",
    "    \n",
    "   \n",
    "    print(\"=\" * 60)\n",
    "    print(\"STEP 1: DATASET ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    dataset_info = get_dataset_info(data_path)\n",
    "    print(\"Dataset Information:\")\n",
    "    for key, value in list(dataset_info.items())[:6]:\n",
    "        if key != 'dtypes':\n",
    "            print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 2: DATA STANDARDIZATION\")\n",
    "    print(\"=\" * 60)\n",
    "    df = load_and_standardize_data(data_path)\n",
    "    print(\"Standardization completed. Data sample:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 3: DATA CLEANING AND TRANSFORMATION\")\n",
    "    print(\"=\" * 60)\n",
    "    df_clean = clean_and_transform_data(df)\n",
    "    print(\"Cleaning completed. Enhanced data sample:\")\n",
    "    print(df_clean.head())\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 4: INSIGHTS GENERATION\")\n",
    "    print(\"=\" * 60)\n",
    "    insights = generate_insights(df_clean)\n",
    "    print(\"Insights generation completed. Key findings:\")\n",
    "    print(f\"- Districts analyzed: {len(insights['district_analysis'])}\")\n",
    "    print(f\"- High-risk districts: {len(insights['risk_analysis'].get('high_risk_districts', {}))}\")\n",
    "    print(f\"- Policy recommendations: {len(insights['policy_recommendations'])}\")\n",
    "    \n",
    "   \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 5: CROSS-SECTOR ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    cross_sector_results = perform_cross_sector_analysis(df_clean)\n",
    "    print(\"Cross-sector analysis completed\")\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STEP 6: REPORT GENERATION\")\n",
    "    print(\"=\" * 60)\n",
    "    report_path = create_comprehensive_report()\n",
    "    if report_path:\n",
    "        print(f\"Comprehensive report generated: {report_path}\")\n",
    "    \n",
    "    \n",
    "    cli = RTGSCLI(df_clean, insights)\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    cli.show_summary()\n",
    "    cli.show_high_risk_districts(top_n=5)\n",
    "    cli.show_policy_recommendations(top_n=5)\n",
    "    cli.show_model_performance()\n",
    "    \n",
    "    \n",
    "    processing_time = datetime.now() - start_time\n",
    "    print(f\"\\nTotal processing time: {processing_time}\")\n",
    "    \n",
    "    \n",
    "    cli.export_results('csv')\n",
    "    cli.export_results('excel')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"RTGS SYSTEM IMPLEMENTATION COMPLETE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Outputs generated:\")\n",
    "    print(f\"1. Standardized data: {Config.OUTPUT_DIR}/standardized/\")\n",
    "    print(f\"2. Cleaned data: {Config.OUTPUT_DIR}/cleaned/\")\n",
    "    print(f\"3. Insights: {Config.OUTPUT_DIR}/insights/\")\n",
    "    print(f\"4. Visualizations: {Config.OUTPUT_DIR}/visualizations/\")\n",
    "    print(f\"5. Models: {Config.OUTPUT_DIR}/models/\")\n",
    "    print(f\"6. Reports: {Config.OUTPUT_DIR}/reports/\")\n",
    "    print(f\"7. Logs and documentation: {Config.OUTPUT_DIR}/logs/\")\n",
    "    \n",
    "    return df_clean, insights, cli\n",
    "\n",
    "print(\"Main execution function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ff697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Run the complete pipeline\n",
    "\n",
    "df_clean, insights, cli = run_rtgs_pipeline()\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DISPLAYING KEY VISUALIZATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "risk_img_path = f\"{Config.OUTPUT_DIR}/visualizations/risk_distribution.png\"\n",
    "if os.path.exists(risk_img_path):\n",
    "    display(HTML(\"<h3>Risk Category Distribution</h3>\"))\n",
    "    display(Image(filename=risk_img_path))\n",
    "\n",
    "\n",
    "rainfall_img_path = f\"{Config.OUTPUT_DIR}/visualizations/district_rainfall.png\"\n",
    "if os.path.exists(rainfall_img_path):\n",
    "    display(HTML(\"<h3>Average Rainfall by District</h3>\"))\n",
    "    display(Image(filename=rainfall_img_path))\n",
    "\n",
    "\n",
    "seasonal_img_path = f\"{Config.OUTPUT_DIR}/visualizations/seasonal_rainfall.png\"\n",
    "if os.path.exists(seasonal_img_path):\n",
    "    display(HTML(\"<h3>Average Rainfall by Season</h3>\"))\n",
    "    display(Image(filename=seasonal_img_path))\n",
    "\n",
    "\n",
    "corr_img_path = f\"{Config.OUTPUT_DIR}/visualizations/correlation_matrix.png\"\n",
    "if os.path.exists(corr_img_path):\n",
    "    display(HTML(\"<h3>Correlation Matrix</h3>\"))\n",
    "    display(Image(filename=corr_img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bdc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Enhanced Professional Dashboard with Multi-Language Support\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML, Javascript\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class EnhancedRTGSDashboard:\n",
    "    \"\"\"Enhanced professional dashboard with multi-language support\"\"\"\n",
    "    \n",
    "    def __init__(self, df, insights):\n",
    "        self.df = df\n",
    "        self.insights = insights\n",
    "        self.current_language = \"English\"\n",
    "        \n",
    "        \n",
    "        self.language_packs = {\n",
    "            \"English\": {\n",
    "                \"dashboard_title\": \"Telangana Climate Risk Dashboard\",\n",
    "                \"dashboard_subtitle\": \"Comprehensive analysis of climate risks and adaptation strategies\",\n",
    "                \"overview_tab\": \"Overview\",\n",
    "                \"district_tab\": \"District Analysis\",\n",
    "                \"risk_tab\": \"Risk Assessment\", \n",
    "                \"recommendations_tab\": \"Recommendations\",\n",
    "                \"chat_tab\": \"Chat with Data\",\n",
    "                \"select_district\": \"Select District:\",\n",
    "                \"select_analysis\": \"Analysis Type:\",\n",
    "                \"select_year\": \"Year:\",\n",
    "                \"risk_factors\": \"Risk Factors\",\n",
    "                \"rainfall_patterns\": \"Rainfall Patterns\",\n",
    "                \"temperature_trends\": \"Temperature Trends\",\n",
    "                \"vulnerability_index\": \"Vulnerability Index\",\n",
    "                \"quick_stats\": \"Quick Stats\",\n",
    "                \"total_districts\": \"Total Districts\",\n",
    "                \"avg_temperature\": \"Avg. Temperature\",\n",
    "                \"avg_rainfall\": \"Avg. Rainfall\",\n",
    "                \"avg_wind_speed\": \"Avg. Wind Speed\",\n",
    "                \"risk_assessment\": \"Risk Assessment\",\n",
    "                \"low_risk\": \"Low Risk (0-4)\",\n",
    "                \"medium_risk\": \"Medium Risk (5-7)\", \n",
    "                \"high_risk\": \"High Risk (8-10)\",\n",
    "                \"action_recommendations\": \"Action Recommendations\",\n",
    "                \"timeframe\": \"Timeframe:\",\n",
    "                \"risk_type\": \"Risk Type:\",\n",
    "                \"all\": \"All\",\n",
    "                \"short_term\": \"Short-term\",\n",
    "                \"medium_term\": \"Medium-term\", \n",
    "                \"long_term\": \"Long-term\",\n",
    "                \"drought\": \"Drought\",\n",
    "                \"flood\": \"Flood\",\n",
    "                \"heatwave\": \"Heatwave\",\n",
    "                \"agriculture\": \"Agriculture\",\n",
    "                \"water\": \"Water\",\n",
    "                \"chat_placeholder\": \"Ask a question about climate data...\",\n",
    "                \"send\": \"Send\",\n",
    "                \"suggestions\": \"Try asking:\",\n",
    "                \"recommendation_engine\": \"Recommendation Engine\",\n",
    "                \"tip\": \"Tip: Use the filters to narrow down recommendations\",\n",
    "                \"email_recommendations\": \"Email Recommendations\",\n",
    "                \"generate_action_plan\": \"Generate Action Plan\",\n",
    "                \"export_pdf\": \"Export to PDF\",\n",
    "                \"climate_assistant\": \"Climate Assistant\",\n",
    "                \"typing\": \"Typing...\",\n",
    "                \"hello\": \"Hello! I'm your Climate Data Assistant.\",\n",
    "                \"assist\": \"How can I assist you today?\",\n",
    "                \"risk_distribution\": \"Risk Distribution\",\n",
    "                \"risk_map\": \"Risk Map Visualization\",\n",
    "                \"for\": \"for\",\n",
    "                \"recommendations\": \"Recommendations\",\n",
    "                \"district_comparison\": \"District Comparison\",\n",
    "                \"trend_analysis\": \"Trend Analysis\",\n",
    "                \"data_export\": \"Data Export\",\n",
    "                \"settings\": \"Settings\"\n",
    "            },\n",
    "            \"Telugu\": {\n",
    "                \"dashboard_title\": \"తెలంగాణ వాతావరణ ప్రమాద డాష్బోర్డ్\",\n",
    "                \"dashboard_subtitle\": \"వాతావరణ ప్రమాదాలు మరియు అనుకూలీకరణ వ్యూహాల సమగ్ర విశ్లేషణ\",\n",
    "                \"overview_tab\": \"అవలోకనం\",\n",
    "                \"district_tab\": \"జిల్లా విశ్లేషణ\",\n",
    "                \"risk_tab\": \"రిస్క్ అంచనా\", \n",
    "                \"recommendations_tab\": \"సిఫార్సులు\",\n",
    "                \"chat_tab\": \"డేటాతో చాట్ చేయండి\",\n",
    "                \"select_district\": \"జిల్లా ఎంచుకోండి:\",\n",
    "                \"select_analysis\": \"విశ్లేషణ రకం:\",\n",
    "                \"select_year\": \"సంవత్సరం:\",\n",
    "                \"risk_factors\": \"రిస్క్ కారకాలు\",\n",
    "                \"rainfall_patterns\": \"వర్షపాతం నమూనాలు\",\n",
    "                \"temperature_trends\": \"ఉష్ణోగ్రత ధోరణులు\",\n",
    "                \"vulnerability_index\": \"అసురక్షిత సూచిక\",\n",
    "                \"quick_stats\": \"శీఘ్ర గణాంకాలు\",\n",
    "                \"total_districts\": \"మొత్తం జిల్లాలు\",\n",
    "                \"avg_temperature\": \"సగటు ఉష్ణోగ్రత\",\n",
    "                \"avg_rainfall\": \"సగటు వర్షపాతం\",\n",
    "                \"avg_wind_speed\": \"సగటు గాలి వేగం\",\n",
    "                \"risk_assessment\": \"రిస్క్ అంచనా\",\n",
    "                \"low_risk\": \"తక్కువ రిస్క్ (0-4)\",\n",
    "                \"medium_risk\": \"మధ్యస్థ రిస్క్ (5-7)\", \n",
    "                \"high_risk\": \"అధిక రిస్క్ (8-10)\",\n",
    "                \"action_recommendations\": \"చర్య సిఫార్సులు\",\n",
    "                \"timeframe\": \"సమయపరిమితి:\",\n",
    "                \"risk_type\": \"రిస్క్ రకం:\",\n",
    "                \"all\": \"అన్నీ\",\n",
    "                \"short_term\": \"స్వల్పకాలిక\",\n",
    "                \"medium_term\": \"మధ్యకాలిక\", \n",
    "                \"long_term\": \"దీర్ఘకాలిక\",\n",
    "                \"drought\": \"బరువు\",\n",
    "                \"flood\": \"వరద\",\n",
    "                \"heatwave\": \"వేడి అల\",\n",
    "                \"agriculture\": \"వ్యవసాయం\",\n",
    "                \"water\": \"నీరు\",\n",
    "                \"chat_placeholder\": \"వాతావరణ డేటా గురించి ప్రశ్నించండి...\",\n",
    "                \"send\": \"పంపించు\",\n",
    "                \"suggestions\": \"ఇలా ప్రశ్నించండి:\",\n",
    "                \"recommendation_engine\": \"సిఫార్సు ఇంజిన్\",\n",
    "                \"tip\": \"చిట్కా: మీ ప్రాధాన్యతల ఆధారంగా సిఫార్సులను శుద్ధీకరించడానికి ఫిల్టర్లను ఉపయోగించండి\",\n",
    "                \"email_recommendations\": \"సిఫార్సులను ఇమెయిల్ చేయండి\",\n",
    "                \"generate_action_plan\": \"చర్య ప్రణాళికను రూపొందించండి\",\n",
    "                \"export_pdf\": \"PDFగా ఎగుమతి చేయండి\",\n",
    "                \"climate_assistant\": \"వాతావరణ సహాయక\",\n",
    "                \"typing\": \"టైప్ చేస్తోంది...\",\n",
    "                \"hello\": \"నమస్కారం! నేను మీ వాతావరణ డేటా సహాయకుడిని.\",\n",
    "                \"assist\": \"ఈరోజు నేను మీకు ఎలా సహాయపడగలను?\",\n",
    "                \"risk_distribution\": \"రిస్క్ పంపిణీ\",\n",
    "                \"risk_map\": \"రిస్క్ మ్యాప్ విజువలైజేషన్\",\n",
    "                \"for\": \"కోసం\",\n",
    "                \"recommendations\": \"సిఫార్సులు\",\n",
    "                \"district_comparison\": \"జిల్లా పోలిక\",\n",
    "                \"trend_analysis\": \"ట్రెండ్ విశ్లేషణ\",\n",
    "                \"data_export\": \"డేటా ఎగుమతి\",\n",
    "                \"settings\": \"సెట్టింగ్స్\"\n",
    "            },\n",
    "            \"Hindi\": {\n",
    "                \"dashboard_title\": \"तेलंगाना जलवायु जोखिम डैशबोर्ड\",\n",
    "                \"dashboard_subtitle\": \"जलवायु जोखिमों और अनुकूलन रणनीतियों का व्यापक विश्लेषण\",\n",
    "                \"overview_tab\": \"अवलोकन\",\n",
    "                \"district_tab\": \"जिला विश्लेषण\",\n",
    "                \"risk_tab\": \"जोखिम आकलन\", \n",
    "                \"recommendations_tab\": \"सिफारिशें\",\n",
    "                \"chat_tab\": \"डेटा के साथ चैट करें\",\n",
    "                \"select_district\": \"जिला चुनें:\",\n",
    "                \"select_analysis\": \"विश्लेषण प्रकार:\",\n",
    "                \"select_year\": \"वर्ष:\",\n",
    "                \"risk_factors\": \"जोखिम कारक\",\n",
    "                \"rainfall_patterns\": \"वर्षा पैटर्न\",\n",
    "                \"temperature_trends\": \"तापमान रुझान\",\n",
    "                \"vulnerability_index\": \"भेद्यता सूचकांक\",\n",
    "                \"quick_stats\": \"त्वरित आँकड़े\",\n",
    "                \"total_districts\": \"कुल जिले\",\n",
    "                \"avg_temperature\": \"औसत तापमान\",\n",
    "                \"avg_rainfall\": \"औसत वर्षा\",\n",
    "                \"avg_wind_speed\": \"औसत हवा की गति\",\n",
    "                \"risk_assessment\": \"जोखिम आकलन\",\n",
    "                \"low_risk\": \"कम जोखिम (0-4)\",\n",
    "                \"medium_risk\": \"मध्यम जोखिम (5-7)\", \n",
    "                \"high_risk\": \"उच्च जोखिम (8-10)\",\n",
    "                \"action_recommendations\": \"कार्रवाई सिफारिशें\",\n",
    "                \"timeframe\": \"समयसीमा:\",\n",
    "                \"risk_type\": \"जोखिम प्रकार:\",\n",
    "                \"all\": \"सभी\",\n",
    "                \"short_term\": \"अल्पकालिक\",\n",
    "                \"medium_term\": \"मध्यम अवधि\", \n",
    "                \"long_term\": \"दीर्घकालिक\",\n",
    "                \"drought\": \"सूखा\",\n",
    "                \"flood\": \"बाढ़\",\n",
    "                \"heatwave\": \"लू\",\n",
    "                \"agriculture\": \"कृषि\",\n",
    "                \"water\": \"पानी\",\n",
    "                \"chat_placeholder\": \"जलवायु डेटा के बारे में प्रश्न पूछें...\",\n",
    "                \"send\": \"भेजें\",\n",
    "                \"suggestions\": \"इस तरह पूछें:\",\n",
    "                \"recommendation_engine\": \"सिफारिश इंजन\",\n",
    "                \"tip\": \"टिप: अपनी प्राथमिकताओं के आधार पर सिफारिशों को निर्दिष्ट करने के लिए फ़िल्टर का उपयोग करें\",\n",
    "                \"email_recommendations\": \"सिफारिशें ईमेल करें\",\n",
    "                \"generate_action_plan\": \"कार्य योजना बनाएं\",\n",
    "                \"export_pdf\": \"PDF निर्यात करें\",\n",
    "                \"climate_assistant\": \"जलवायु सहायक\",\n",
    "                \"typing\": \"टाइप कर रहा है...\",\n",
    "                \"hello\": \"नमस्ते! मैं आपका जलवायु डेटा सहायक हूं।\",\n",
    "                \"assist\": \"आज मैं आपकी कैसे सहायता कर सकता हूं?\",\n",
    "                \"risk_distribution\": \"जोखिम वितरण\",\n",
    "                \"risk_map\": \"जोखिम मानचित्र दृश्य\",\n",
    "                \"for\": \"के लिए\",\n",
    "                \"recommendations\": \"सिफारिशें\",\n",
    "                \"district_comparison\": \"जिला तुलना\",\n",
    "                \"trend_analysis\": \"ट्रेंड विश्लेषण\",\n",
    "                \"data_export\": \"डेटा निर्यात\",\n",
    "                \"settings\": \"सेटिंग्स\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        \n",
    "        self.setup_dashboard()\n",
    "    \n",
    "    def t(self, key):\n",
    "        \"\"\"Translate a key to the current language\"\"\"\n",
    "        return self.language_packs[self.current_language].get(key, key)\n",
    "    \n",
    "    def setup_dashboard(self):\n",
    "        \"\"\"Setup the complete dashboard with all components\"\"\"\n",
    "        \n",
    "        css_styles = \"\"\"\n",
    "        <style>\n",
    "            .dashboard-container {\n",
    "                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "                color: #333;\n",
    "                margin: 0;\n",
    "                padding: 0;\n",
    "            }\n",
    "            .dashboard-header {\n",
    "                background: linear-gradient(135deg, #1a2a6c, #b21f1f, #fdbb2d);\n",
    "                color: white;\n",
    "                padding: 20px;\n",
    "                border-radius: 10px;\n",
    "                margin-bottom: 20px;\n",
    "                text-align: center;\n",
    "                box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .metric-card {\n",
    "                background: white;\n",
    "                padding: 15px;\n",
    "                border-radius: 10px;\n",
    "                box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
    "                text-align: center;\n",
    "                transition: transform 0.3s ease;\n",
    "                margin: 10px;\n",
    "            }\n",
    "            .metric-card:hover {\n",
    "                transform: translateY(-5px);\n",
    "                box-shadow: 0 6px 12px rgba(0,0,0,0.15);\n",
    "            }\n",
    "            .tab-content {\n",
    "                padding: 20px;\n",
    "                background: #f8f9fa;\n",
    "                border-radius: 0 0 10px 10px;\n",
    "            }\n",
    "            .chat-container {\n",
    "                height: 400px;\n",
    "                overflow-y: auto;\n",
    "                background: white;\n",
    "                border-radius: 10px;\n",
    "                padding: 15px;\n",
    "                box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .user-message {\n",
    "                background: #e3f2fd;\n",
    "                padding: 10px 15px;\n",
    "                border-radius: 18px 18px 0 18px;\n",
    "                margin: 10px 0;\n",
    "                max-width: 80%;\n",
    "                margin-left: auto;\n",
    "            }\n",
    "            .bot-message {\n",
    "                background: #f5f5f5;\n",
    "                padding: 10px 15px;\n",
    "                border-radius: 18px 18px 18px 0;\n",
    "                margin: 10px 0;\n",
    "                max-width: 80%;\n",
    "            }\n",
    "            .risk-low {\n",
    "                color: #28a745;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .risk-medium {\n",
    "                color: #ffc107;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .risk-high {\n",
    "                color: #dc3545;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .suggestion-chip {\n",
    "                display: inline-block;\n",
    "                background: #e9ecef;\n",
    "                padding: 5px 10px;\n",
    "                border-radius: 20px;\n",
    "                margin: 5px;\n",
    "                cursor: pointer;\n",
    "                transition: background 0.3s;\n",
    "                font-size: 12px;\n",
    "            }\n",
    "            .suggestion-chip:hover {\n",
    "                background: #dee2e6;\n",
    "            }\n",
    "            .widget-label {\n",
    "                font-weight: bold;\n",
    "                margin-bottom: 5px;\n",
    "            }\n",
    "            .tab-button {\n",
    "                border-radius: 8px 8px 0 0 !important;\n",
    "            }\n",
    "            .filter-panel {\n",
    "                background: white;\n",
    "                padding: 15px;\n",
    "                border-radius: 10px;\n",
    "                box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "                margin-bottom: 15px;\n",
    "            }\n",
    "            .loading-indicator {\n",
    "                display: inline-block;\n",
    "                width: 20px;\n",
    "                height: 20px;\n",
    "                border: 3px solid rgba(255,255,255,.3);\n",
    "                border-radius: 50%;\n",
    "                border-top-color: #fff;\n",
    "                animation: spin 1s ease-in-out infinite;\n",
    "            }\n",
    "            @keyframes spin {\n",
    "                to { transform: rotate(360deg); }\n",
    "            }\n",
    "            .map-container {\n",
    "                height: 500px;\n",
    "                border-radius: 10px;\n",
    "                overflow: hidden;\n",
    "                box-shadow: 0 4px 8px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            .smooth-transition {\n",
    "                transition: all 0.3s ease;\n",
    "            }\n",
    "            .action-button {\n",
    "                background: linear-gradient(135deg, #6a11cb 0%, #2575fc 100%);\n",
    "                color: white;\n",
    "                border: none;\n",
    "                padding: 10px 20px;\n",
    "                border-radius: 5px;\n",
    "                cursor: pointer;\n",
    "                transition: all 0.3s ease;\n",
    "                margin: 5px;\n",
    "            }\n",
    "            .action-button:hover {\n",
    "                transform: translateY(-2px);\n",
    "                box-shadow: 0 4px 8px rgba(0,0,0,0.2);\n",
    "            }\n",
    "            .sidebar {\n",
    "                background: white;\n",
    "                padding: 15px;\n",
    "                border-radius: 10px;\n",
    "                box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "                height: fit-content;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\"\n",
    "        \n",
    "       \n",
    "        display(HTML(css_styles))\n",
    "        \n",
    "        \n",
    "        main_container = widgets.VBox(layout=widgets.Layout(width='100%', padding='10px'))\n",
    "        \n",
    "        \n",
    "        header_html = f\"\"\"\n",
    "        <div class=\"dashboard-header\">\n",
    "            <h1>🌍 {self.t('dashboard_title')}</h1>\n",
    "            <p>{self.t('dashboard_subtitle')}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        header = widgets.HTML(value=header_html)\n",
    "        \n",
    "        # Create tabs for different sections\n",
    "        tab_titles = [self.t('overview_tab'), self.t('district_tab'), self.t('risk_tab'), \n",
    "                     self.t('recommendations_tab'), self.t('chat_tab')]\n",
    "        tabs = widgets.Tab(children=[widgets.Output() for _ in tab_titles])\n",
    "        for i, title in enumerate(tab_titles):\n",
    "            tabs.set_title(i, title)\n",
    "        \n",
    "        # Define content for each tab\n",
    "        with tabs.children[0]:\n",
    "            clear_output()\n",
    "            self.create_overview_tab()\n",
    "        \n",
    "        with tabs.children[1]:\n",
    "            clear_output()\n",
    "            self.create_district_analysis_tab()\n",
    "        \n",
    "        with tabs.children[2]:\n",
    "            clear_output()\n",
    "            self.create_risk_assessment_tab()\n",
    "        \n",
    "        with tabs.children[3]:\n",
    "            clear_output()\n",
    "            self.create_recommendations_tab()\n",
    "        \n",
    "        with tabs.children[4]:\n",
    "            clear_output()\n",
    "            self.create_chat_tab()\n",
    "        \n",
    "        # Language selector\n",
    "        language_selector = widgets.Dropdown(\n",
    "            options=['English', 'Telugu', 'Hindi'],\n",
    "            value=self.current_language,\n",
    "            description='Language:',\n",
    "            disabled=False,\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='300px', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        def update_language(change):\n",
    "            self.current_language = change['new']\n",
    "            # Refresh all tabs\n",
    "            with tabs.children[0]:\n",
    "                clear_output()\n",
    "                self.create_overview_tab()\n",
    "            with tabs.children[1]:\n",
    "                clear_output()\n",
    "                self.create_district_analysis_tab()\n",
    "            with tabs.children[2]:\n",
    "                clear_output()\n",
    "                self.create_risk_assessment_tab()\n",
    "            with tabs.children[3]:\n",
    "                clear_output()\n",
    "                self.create_recommendations_tab()\n",
    "            with tabs.children[4]:\n",
    "                clear_output()\n",
    "                self.create_chat_tab()\n",
    "            \n",
    "            # Update header\n",
    "            header_html = f\"\"\"\n",
    "            <div class=\"dashboard-header\">\n",
    "                <h1>🌍 {self.t('dashboard_title')}</h1>\n",
    "                <p>{self.t('dashboard_subtitle')}</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            header.value = header_html\n",
    "        \n",
    "        language_selector.observe(update_language, names='value')\n",
    "        \n",
    "        \n",
    "        main_container.children = [header, language_selector, tabs]\n",
    "        \n",
    "      \n",
    "        display(main_container)\n",
    "    \n",
    "    def create_overview_tab(self):\n",
    "        \"\"\"Create the overview tab content\"\"\"\n",
    "        display(HTML(f\"<h2 style='color:#1f77b4; text-align:center;'>{self.t('overview_tab')}</h2>\"))\n",
    "        display(HTML(f\"<p style='text-align:center;'>{self.t('dashboard_subtitle')}</p>\"))\n",
    "        \n",
    "        \n",
    "        total_districts = self.df['district'].nunique() if 'district' in self.df.columns else 0\n",
    "        avg_temp = self.df['avg_temp'].mean() if 'avg_temp' in self.df.columns else 0\n",
    "        avg_rainfall = self.df['rainfall_mm'].mean() if 'rainfall_mm' in self.df.columns else 0\n",
    "        avg_wind_speed = self.df['wind_speed'].mean() if 'wind_speed' in self.df.columns else 0\n",
    "        \n",
    "        metrics_html = f\"\"\"\n",
    "        <div style='display: flex; justify-content: space-around; margin: 20px 0; flex-wrap: wrap;'>\n",
    "            <div class=\"metric-card\" style='background: linear-gradient(135deg, #6a11cb 0%, #2575fc 100%); color: white; width: 22%;'>\n",
    "                <h3>{total_districts}</h3>\n",
    "                <p>{self.t('total_districts')}</p>\n",
    "            </div>\n",
    "            <div class=\"metric-card\" style='background: linear-gradient(135deg, #FF512F 0%, #F09819 100%); color: white; width: 22%;'>\n",
    "                <h3>{avg_wind_speed:.1f} km/h</h3>\n",
    "                <p>{self.t('avg_wind_speed')}</p>\n",
    "            </div>\n",
    "            <div class=\"metric-card\" style='background: linear-gradient(135deg, #0ba360 0%, #3cba92 100%); color: white; width: 22%;'>\n",
    "                <h3>{avg_rainfall:.1f} mm</h3>\n",
    "                <p>{self.t('avg_rainfall')}</p>\n",
    "            </div>\n",
    "            <div class=\"metric-card\" style='background: linear-gradient(135deg, #C471F5 0%, #FA71CD 100%); color: white; width: 22%;'>\n",
    "                <h3>{avg_temp:.1f}°C</h3>\n",
    "                <p>{self.t('avg_temperature')}</p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(metrics_html))\n",
    "        \n",
    "       \n",
    "        col1, col2 = widgets.Output(), widgets.Output()\n",
    "        \n",
    "        with col1:\n",
    "            \n",
    "            if 'risk_category' in self.df.columns:\n",
    "                risk_counts = self.df['risk_category'].value_counts()\n",
    "                fig = px.pie(values=risk_counts.values, names=risk_counts.index, \n",
    "                            title=self.t('risk_distribution'))\n",
    "                fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "                fig.show()\n",
    "        \n",
    "        with col2:\n",
    "            \n",
    "            if 'district' in self.df.columns and 'ari_normalized' in self.df.columns:\n",
    "                district_risk = self.df.groupby('district')['ari_normalized'].mean().reset_index()\n",
    "                district_risk = district_risk.sort_values('ari_normalized', ascending=False).head(10)\n",
    "                \n",
    "                fig = px.bar(district_risk, x='district', y='ari_normalized', \n",
    "                            title='Top 10 Districts by Risk Index',\n",
    "                            color='ari_normalized',\n",
    "                            color_continuous_scale='RdYlGn_r')\n",
    "                fig.update_layout(xaxis_title='District', yaxis_title='Risk Index')\n",
    "                fig.show()\n",
    "        \n",
    "       \n",
    "        display(widgets.HBox([col1, col2]))\n",
    "        \n",
    "        \n",
    "        display(HTML(\"<h3 style='color:#1f77b4; text-align:center; margin-top:30px;'>Climate Trends Over Time</h3>\"))\n",
    "        \n",
    "        trend_output = widgets.Output()\n",
    "        with trend_output:\n",
    "            if 'year' in self.df.columns:\n",
    "                # Create a line chart showing trends over time\n",
    "                yearly_data = self.df.groupby('year').agg({\n",
    "                    'rainfall_mm': 'mean',\n",
    "                    'avg_temp': 'mean',\n",
    "                    'ari_normalized': 'mean'\n",
    "                }).reset_index()\n",
    "                \n",
    "                fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "                \n",
    "\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=yearly_data['year'], y=yearly_data['rainfall_mm'], name=\"Rainfall (mm)\", line=dict(color='blue')),\n",
    "                    secondary_y=False,\n",
    "                )\n",
    "                \n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=yearly_data['year'], y=yearly_data['avg_temp'], name=\"Temperature (°C)\", line=dict(color='red')),\n",
    "                    secondary_y=True,\n",
    "                )\n",
    "                \n",
    "                \n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=yearly_data['year'], y=yearly_data['ari_normalized'], name=\"Risk Index\", line=dict(color='green')),\n",
    "                    secondary_y=False,\n",
    "                )\n",
    "                \n",
    "                \n",
    "                fig.update_xaxes(title_text=\"Year\")\n",
    "                \n",
    "                \n",
    "                fig.update_yaxes(title_text=\"Rainfall (mm) / Risk Index\", secondary_y=False)\n",
    "                fig.update_yaxes(title_text=\"Temperature (°C)\", secondary_y=True)\n",
    "                \n",
    "                fig.update_layout(title_text=\"Climate Trends Over Time\")\n",
    "                fig.show()\n",
    "        \n",
    "        display(trend_output)\n",
    "    \n",
    "    def create_district_analysis_tab(self):\n",
    "        \"\"\"Create the district analysis tab content\"\"\"\n",
    "        display(HTML(f\"<h2 style='color:#1f77b4; text-align:center;'>{self.t('district_tab')}</h2>\"))\n",
    "        \n",
    "        \n",
    "        left_panel = widgets.VBox(layout=widgets.Layout(width='30%', padding='10px'))\n",
    "        right_panel = widgets.Output(layout=widgets.Layout(width='70%'))\n",
    "        \n",
    "        \n",
    "        district_options = ['All'] + sorted(self.df['district'].unique().tolist()) if 'district' in self.df.columns else ['All']\n",
    "        district_selector = widgets.Dropdown(\n",
    "            options=district_options,\n",
    "            value='All',\n",
    "            description=self.t('select_district'),\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        \n",
    "        \n",
    "        analysis_options = [self.t('risk_factors'), self.t('rainfall_patterns'), \n",
    "                           self.t('temperature_trends'), self.t('vulnerability_index')]\n",
    "        analysis_selector = widgets.Dropdown(\n",
    "            options=analysis_options,\n",
    "            value=self.t('risk_factors'),\n",
    "            description=self.t('select_analysis'),\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        \n",
    "        \n",
    "        year_options = ['All'] + sorted(self.df['year'].unique().tolist()) if 'year' in self.df.columns else ['All']\n",
    "        year_selector = widgets.Dropdown(\n",
    "            options=year_options,\n",
    "            value='All',\n",
    "            description=self.t('select_year'),\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        \n",
    "        \n",
    "        total_districts = self.df['district'].nunique() if 'district' in self.df.columns else 0\n",
    "        avg_temp = self.df['avg_temp'].mean() if 'avg_temp' in self.df.columns else 0\n",
    "        avg_rainfall = self.df['rainfall_mm'].mean() if 'rainfall_mm' in self.df.columns else 0\n",
    "        \n",
    "        stats_html = f\"\"\"\n",
    "        <div class=\"metric-card\">\n",
    "            <h4>{self.t('quick_stats')}</h4>\n",
    "            <p>📊 {self.t('total_districts')}: {total_districts}</p>\n",
    "            <p>🌡️ {self.t('avg_temperature')}: {avg_temp:.1f}°C</p>\n",
    "            <p>🌧️ {self.t('avg_rainfall')}: {avg_rainfall:.1f} mm</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        stats_widget = widgets.HTML(value=stats_html)\n",
    "        \n",
    "        \n",
    "        compare_button = widgets.Button(\n",
    "            description=self.t('district_comparison'),\n",
    "            button_style='info',\n",
    "            tooltip='Compare selected district with others',\n",
    "            layout=widgets.Layout(width='90%', margin='10px 0')\n",
    "        )\n",
    "        \n",
    "        \n",
    "        left_panel.children = [district_selector, analysis_selector, year_selector, stats_widget, compare_button]\n",
    "        \n",
    "       \n",
    "        def update_analysis(change):\n",
    "            with right_panel:\n",
    "                clear_output()\n",
    "                district = district_selector.value\n",
    "                analysis_type = analysis_selector.value\n",
    "                year = year_selector.value\n",
    "                \n",
    "                display(HTML(f\"<h3 style='color:#1f77b4;'>{analysis_type} {self.t('for')} {district if district != 'All' else 'All Districts'} ({year if year != 'All' else 'All Years'})</h3>\"))\n",
    "                \n",
    "                # Filter data based on selections\n",
    "                filtered_df = self.df.copy()\n",
    "                \n",
    "                if district != 'All':\n",
    "                    filtered_df = filtered_df[filtered_df['district'] == district]\n",
    "                \n",
    "                if year != 'All':\n",
    "                    filtered_df = filtered_df[filtered_df['year'] == year]\n",
    "                \n",
    "                # Generate appropriate visualization based on analysis type\n",
    "                if analysis_type == self.t('risk_factors'):\n",
    "                    self.create_risk_factors_visualization(filtered_df, district)\n",
    "                elif analysis_type == self.t('rainfall_patterns'):\n",
    "                    self.create_rainfall_visualization(filtered_df, district)\n",
    "                elif analysis_type == self.t('temperature_trends'):\n",
    "                    self.create_temperature_visualization(filtered_df, district)\n",
    "                elif analysis_type == self.t('vulnerability_index'):\n",
    "                    self.create_vulnerability_visualization(filtered_df, district)\n",
    "        \n",
    "        def show_comparison(b):\n",
    "            with right_panel:\n",
    "                clear_output()\n",
    "                district = district_selector.value\n",
    "                if district == 'All':\n",
    "                    display(HTML(\"<p style='color:red;'>Please select a specific district to compare.</p>\"))\n",
    "                    return\n",
    "                \n",
    "                display(HTML(f\"<h3 style='color:#1f77b4;'>{self.t('district_comparison')}: {district} vs. Other Districts</h3>\"))\n",
    "                \n",
    "                # Create comparison visualizations\n",
    "                if 'ari_normalized' in self.df.columns:\n",
    "                    \n",
    "                    district_risk = self.df[self.df['district'] == district]['ari_normalized'].mean()\n",
    "                    \n",
    "                    \n",
    "                    other_risk = self.df[self.df['district'] != district]['ari_normalized'].mean()\n",
    "                    \n",
    "                  \n",
    "                    fig = px.bar(x=[district, 'Other Districts'], y=[district_risk, other_risk],\n",
    "                                labels={'x': 'District', 'y': 'Risk Index'},\n",
    "                                title=f'Risk Comparison: {district} vs. Other Districts',\n",
    "                                color=[district, 'Other Districts'],\n",
    "                                color_discrete_map={district: '#FF6B6B', 'Other Districts': '#4ECDC4'})\n",
    "                    fig.show()\n",
    "        \n",
    "        \n",
    "        district_selector.observe(update_analysis, names='value')\n",
    "        analysis_selector.observe(update_analysis, names='value')\n",
    "        year_selector.observe(update_analysis, names='value')\n",
    "        compare_button.on_click(show_comparison)\n",
    "        \n",
    "        \n",
    "        display(widgets.HBox([left_panel, right_panel]))\n",
    "        update_analysis(None)  # Initial update\n",
    "    \n",
    "    def create_risk_factors_visualization(self, filtered_df, district):\n",
    "        \"\"\"Create risk factors visualization\"\"\"\n",
    "        if 'risk_category' in filtered_df.columns:\n",
    "            risk_counts = filtered_df['risk_category'].value_counts()\n",
    "            fig = px.pie(values=risk_counts.values, names=risk_counts.index, \n",
    "                        title=f'Risk Distribution for {district if district != \"All\" else \"All Districts\"}')\n",
    "            fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "            fig.show()\n",
    "        \n",
    "        \n",
    "        risk_html = f\"\"\"\n",
    "        <div style='margin-top: 20px;'>\n",
    "            <h4>{self.t('risk_assessment')}</h4>\n",
    "            <p><span class=\"risk-low\">{self.t('low_risk')}</span>: Minimal immediate action needed</p>\n",
    "            <p><span class=\"risk-medium\">{self.t('medium_risk')}</span>: Monitoring and planning recommended</p>\n",
    "            <p><span class=\"risk-high\">{self.t('high_risk')}</span>: Immediate action required</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(risk_html))\n",
    "    \n",
    "    def create_rainfall_visualization(self, filtered_df, district):\n",
    "        \"\"\"Create rainfall visualization\"\"\"\n",
    "        if 'month' in filtered_df.columns and 'rainfall_mm' in filtered_df.columns:\n",
    "            monthly_rain = filtered_df.groupby('month')['rainfall_mm'].mean()\n",
    "            fig = px.bar(x=monthly_rain.index, y=monthly_rain.values, \n",
    "                        labels={'x': 'Month', 'y': 'Rainfall (mm)'},\n",
    "                        title=f'Average Monthly Rainfall for {district if district != \"All\" else \"All Districts\"}',\n",
    "                        color=monthly_rain.values,\n",
    "                        color_continuous_scale='Blues')\n",
    "            fig.show()\n",
    "        \n",
    "        if 'rainfall_mm' in filtered_df.columns:\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='margin-top: 20px;'>\n",
    "                <h4>Rainfall Statistics</h4>\n",
    "                <p>📊 Average Rainfall: <b>{filtered_df['rainfall_mm'].mean():.1f} mm</b></p>\n",
    "                <p>📈 Maximum Rainfall: <b>{filtered_df['rainfall_mm'].max():.1f} mm</b></p>\n",
    "                <p>📉 Minimum Rainfall: <b>{filtered_df['rainfall_mm'].min():.1f} mm</b></p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    \n",
    "    def create_temperature_visualization(self, filtered_df, district):\n",
    "        \"\"\"Create temperature visualization\"\"\"\n",
    "        if 'avg_temp' in filtered_df.columns:\n",
    "            fig = px.histogram(filtered_df, x='avg_temp', \n",
    "                             title=f'Temperature Distribution for {district if district != \"All\" else \"All Districts\"}',\n",
    "                             labels={'avg_temp': 'Temperature (°C)'},\n",
    "                             color_discrete_sequence=['#FF6B6B'])\n",
    "            fig.show()\n",
    "        \n",
    "        if 'avg_temp' in filtered_df.columns:\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='margin-top: 20px;'>\n",
    "                <h4>Temperature Statistics</h4>\n",
    "                <p>📊 Average Temperature: <b>{filtered_df['avg_temp'].mean():.1f}°C</b></p>\n",
    "                <p>📈 Maximum Temperature: <b>{filtered_df['avg_temp'].max():.1f}°C</b></p>\n",
    "                <p>📉 Minimum Temperature: <b>{filtered_df['avg_temp'].min():.1f}°C</b></p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    \n",
    "    def create_vulnerability_visualization(self, filtered_df, district):\n",
    "        \"\"\"Create vulnerability visualization\"\"\"\n",
    "        if 'ari_normalized' in filtered_df.columns:\n",
    "            fig = px.box(filtered_df, y='ari_normalized', \n",
    "                       title=f'Risk Index Distribution for {district if district != \"All\" else \"All Districts\"}',\n",
    "                       labels={'ari_normalized': 'Risk Index'},\n",
    "                       color_discrete_sequence=['#4ECDC4'])\n",
    "            fig.show()\n",
    "        \n",
    "        if 'ari_normalized' in filtered_df.columns:\n",
    "            display(HTML(f\"\"\"\n",
    "            <div style='margin-top: 20px;'>\n",
    "                <h4>Risk Index Statistics</h4>\n",
    "                <p>📊 Average Risk Index: <b>{filtered_df['ari_normalized'].mean():.1f}</b></p>\n",
    "                <p>📈 Maximum Risk Index: <b>{filtered_df['ari_normalized'].max():.1f}</b></p>\n",
    "                <p>📉 Minimum Risk Index: <b>{filtered_df['ari_normalized'].min():.1f}</b></p>\n",
    "            </div>\n",
    "            \"\"\"))\n",
    "    \n",
    "    def create_risk_assessment_tab(self):\n",
    "        \"\"\"Create the risk assessment tab content\"\"\"\n",
    "        display(HTML(f\"<h2 style='color:#1f77b4; text-align:center;'>{self.t('risk_tab')}</h2>\"))\n",
    "        \n",
    "        # Create risk visualization\n",
    "        if 'district' in self.df.columns and 'ari_normalized' in self.df.columns:\n",
    "            district_risk = self.df.groupby('district')['ari_normalized'].mean().reset_index()\n",
    "            \n",
    "            # Create a bubble chart\n",
    "            fig = px.scatter(\n",
    "                district_risk, \n",
    "                x='district', \n",
    "                y='ari_normalized',\n",
    "                size='ari_normalized',\n",
    "                color='ari_normalized',\n",
    "                color_continuous_scale='RdYlGn_r',\n",
    "                title='Climate Risk by District',\n",
    "                labels={'ari_normalized': 'Risk Index', 'district': 'District'}\n",
    "            )\n",
    "            fig.update_layout(xaxis_tickangle=-45)\n",
    "            fig.show()\n",
    "        \n",
    "        # Create an interactive risk map\n",
    "        display(HTML(f\"<h3 style='color:#1f77b4; text-align:center;'>{self.t('risk_map')}</h3>\"))\n",
    "        \n",
    "        # Create a map visualization using Plotly\n",
    "        map_output = widgets.Output()\n",
    "        with map_output:\n",
    "            # Create sample coordinates for Telangana districts (in a real scenario, use actual coordinates)\n",
    "            district_coords = {\n",
    "                'Adilabad': (19.6667, 78.5333),\n",
    "                'Hyderabad': (17.3850, 78.4867),\n",
    "                'Karimnagar': (18.4333, 79.1500),\n",
    "                'Khammam': (17.2473, 80.1514),\n",
    "                'Mahabubnagar': (16.7333, 77.9833),\n",
    "                'Medak': (18.0333, 78.2667),\n",
    "                'Nalgonda': (17.0500, 79.2667),\n",
    "                'Nizamabad': (18.6667, 78.1167),\n",
    "                'Rangareddy': (17.3667, 78.4667),\n",
    "                'Warangal': (17.9756, 79.6011)\n",
    "            }\n",
    "            \n",
    "            # Create a DataFrame with district coordinates\n",
    "            if 'district' in self.df.columns and 'ari_normalized' in self.df.columns:\n",
    "                district_risk = self.df.groupby('district')['ari_normalized'].mean().reset_index()\n",
    "                \n",
    "                # Add coordinates\n",
    "                district_risk['lat'] = district_risk['district'].apply(lambda x: district_coords.get(x, (0, 0))[0])\n",
    "                district_risk['lon'] = district_risk['district'].apply(lambda x: district_coords.get(x, (0, 0))[1])\n",
    "                \n",
    "                # Create the map\n",
    "                fig = px.scatter_mapbox(\n",
    "                    district_risk,\n",
    "                    lat=\"lat\",\n",
    "                    lon=\"lon\",\n",
    "                    hover_name=\"district\",\n",
    "                    hover_data={\"ari_normalized\": True, \"lat\": False, \"lon\": False},\n",
    "                    color=\"ari_normalized\",\n",
    "                    size=\"ari_normalized\",\n",
    "                    color_continuous_scale=\"RdYlGn_r\",\n",
    "                    size_max=30,\n",
    "                    zoom=6,\n",
    "                    height=500,\n",
    "                    title=\"District Risk Map\"\n",
    "                )\n",
    "                \n",
    "                fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "                fig.update_layout(margin={\"r\": 0, \"t\": 30, \"l\": 0, \"b\": 0})\n",
    "                fig.show()\n",
    "        \n",
    "        display(map_output)\n",
    "        \n",
    "        # Add risk assessment legend\n",
    "        risk_html = f\"\"\"\n",
    "        <div style='background-color: #f8f9fa; padding: 15px; border-radius: 10px; margin-top: 20px;'>\n",
    "            <h3>{self.t('risk_assessment')} Legend</h3>\n",
    "            <p><span class=\"risk-low\">{self.t('low_risk')}</span>: Minimal immediate action needed</p>\n",
    "            <p><span class=\"risk-medium\">{self.t('medium_risk')}</span>: Monitoring and planning recommended</p>\n",
    "            <p><span class=\"risk-high\">{self.t('high_risk')}</span>: Immediate action required</p>\n",
    "            \n",
    "            <div style='margin-top: 20px;'>\n",
    "                <h4>Risk Factors Considered</h4>\n",
    "                <ul>\n",
    "                    <li>Historical climate data</li>\n",
    "                    <li>Extreme weather events frequency</li>\n",
    "                    <li>Agricultural vulnerability</li>\n",
    "                    <li>Water resource availability</li>\n",
    "                    <li>Infrastructure resilience</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(HTML(risk_html))\n",
    "    \n",
    "    def create_recommendations_tab(self):\n",
    "        \"\"\"Create the recommendations tab content\"\"\"\n",
    "        display(HTML(f\"<h2 style='color:#1f77b4; text-align:center;'>{self.t('recommendations_tab')}</h2>\"))\n",
    "        \n",
    "        # Create a two-column layout\n",
    "        rec_left = widgets.VBox(layout=widgets.Layout(width='40%', padding='10px'))\n",
    "        rec_right = widgets.Output(layout=widgets.Layout(width='60%'))\n",
    "        \n",
    "        # District selector\n",
    "        district_options = ['All'] + sorted(self.df['district'].unique().tolist()) if 'district' in self.df.columns else ['All']\n",
    "        rec_district = widgets.Dropdown(\n",
    "            options=district_options,\n",
    "            value='All',\n",
    "            description=self.t('select_district'),\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        \n",
    "        # Priority filter\n",
    "        priority_options = [self.t('all'), self.t('short_term'), self.t('medium_term'), self.t('long_term')]\n",
    "        priority_filter = widgets.Dropdown(\n",
    "            options=priority_options,\n",
    "            value=self.t('all'),\n",
    "            description=self.t('timeframe'),\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        \n",
    "        # Risk type filter\n",
    "        risk_type_options = [self.t('all'), self.t('drought'), self.t('flood'), self.t('heatwave'), self.t('agriculture'), self.t('water')]\n",
    "        risk_type_filter = widgets.Dropdown(\n",
    "            options=risk_type_options,\n",
    "            value=self.t('all'),\n",
    "            description=self.t('risk_type'),\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        \n",
    "        # Add info cards\n",
    "        info_html = f\"\"\"\n",
    "        <div class=\"metric-card\">\n",
    "            <h4>{self.t('recommendation_engine')}</h4>\n",
    "            <p>Our AI-powered system analyzes multiple risk factors to provide tailored recommendations for each district.</p>\n",
    "            <div style='background: #e7f3ff; padding: 10px; border-radius: 5px; margin: 10px 0;'>\n",
    "                <p style='margin: 0;'>💡 <b>{self.t('tip')}</b></p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        info_widget = widgets.HTML(value=info_html)\n",
    "        \n",
    "        # Add to left panel\n",
    "        rec_left.children = [rec_district, priority_filter, risk_type_filter, info_widget]\n",
    "        \n",
    "        # Recommendation display function\n",
    "        def show_recommendations(district, priority, risk_type):\n",
    "            with rec_right:\n",
    "                clear_output()\n",
    "                \n",
    "                # Sample recommendations based on district\n",
    "                recommendations = {\n",
    "                    'Adilabad': [\n",
    "                        {\"text\": \"Implement water conservation measures to address drought risk\", \"priority\": self.t('short_term'), \"risk\": self.t('drought')},\n",
    "                        {\"text\": \"Develop early warning systems for heatwaves\", \"priority\": self.t('medium_term'), \"risk\": self.t('heatwave')},\n",
    "                        {\"text\": \"Promote drought-resistant crops in agricultural planning\", \"priority\": self.t('long_term'), \"risk\": self.t('agriculture')},\n",
    "                        {\"text\": \"Improve irrigation infrastructure efficiency\", \"priority\": self.t('medium_term'), \"risk\": self.t('agriculture')},\n",
    "                        {\"text\": \"Create community water management committees\", \"priority\": self.t('short_term'), \"risk\": self.t('drought')}\n",
    "                    ],\n",
    "                    'Hyderabad': [\n",
    "                        {\"text\": \"Enhance urban drainage infrastructure to handle monsoon rains\", \"priority\": self.t('medium_term'), \"risk\": self.t('flood')},\n",
    "                        {\"text\": \"Create green spaces to reduce urban heat island effect\", \"priority\": self.t('long_term'), \"risk\": self.t('heatwave')},\n",
    "                        {\"text\": \"Develop flood risk mapping for urban planning\", \"priority\": self.t('short_term'), \"risk\": self.t('flood')},\n",
    "                        {\"text\": \"Implement rainwater harvesting systems in public buildings\", \"priority\": self.t('medium_term'), \"risk\": self.t('water')},\n",
    "                        {\"text\": \"Promote use of reflective materials in construction\", \"priority\": self.t('long_term'), \"risk\": self.t('heatwave')}\n",
    "                    ],\n",
    "                    'Karimnagar': [\n",
    "                        {\"text\": \"Improve irrigation efficiency in agricultural areas\", \"priority\": self.t('short_term'), \"risk\": self.t('agriculture')},\n",
    "                        {\"text\": \"Develop community-based disaster risk reduction programs\", \"priority\": self.t('medium_term'), \"risk\": self.t('all')},\n",
    "                        {\"text\": \"Promote agroforestry to improve soil water retention\", \"priority\": self.t('long_term'), \"risk\": self.t('agriculture')},\n",
    "                        {\"text\": \"Diversify crop patterns to reduce climate dependence\", \"priority\": self.t('medium_term'), \"risk\": self.t('agriculture')},\n",
    "                        {\"text\": \"Establish weather-based crop insurance schemes\", \"priority\": self.t('short_term'), \"risk\": self.t('agriculture')}\n",
    "                    ]\n",
    "                }\n",
    "                \n",
    "                # Default recommendations if district not in list\n",
    "                default_recs = [\n",
    "                    {\"text\": \"Develop integrated water resource management plan\", \"priority\": self.t('medium_term'), \"risk\": self.t('water')},\n",
    "                    {\"text\": \"Strengthen early warning systems for extreme weather events\", \"priority\": self.t('short_term'), \"risk\": self.t('all')},\n",
    "                    {\"text\": \"Promote climate-resilient agricultural practices\", \"priority\": self.t('long_term'), \"risk\": self.t('agriculture')}\n",
    "                ]\n",
    "                \n",
    "                dist_recs = recommendations.get(district, default_recs) if district != self.t('all') else default_recs\n",
    "                \n",
    "                # Filter based on priority and risk type\n",
    "                filtered_recs = []\n",
    "                for rec in dist_recs:\n",
    "                    if (priority == self.t('all') or rec[\"priority\"] == priority) and \\\n",
    "                       (risk_type == self.t('all') or rec[\"risk\"] == risk_type or rec[\"risk\"] == self.t('all')):\n",
    "                        filtered_recs.append(rec)\n",
    "                \n",
    "                display(HTML(f\"<h3 style='color:#1f77b4;'>{self.t('action_recommendations')} {self.t('for')} {district if district != self.t('all') else 'All Districts'}</h3>\"))\n",
    "                \n",
    "                if not filtered_recs:\n",
    "                    display(HTML(\"<p>No recommendations match your filters. Try adjusting the filters above.</p>\"))\n",
    "                    return\n",
    "                \n",
    "                # Group by priority\n",
    "                priority_groups = {self.t('short_term'): [], self.t('medium_term'): [], self.t('long_term'): []}\n",
    "                for rec in filtered_recs:\n",
    "                    priority_groups[rec[\"priority\"]].append(rec)\n",
    "                \n",
    "                for prio, recs in priority_groups.items():\n",
    "                    if recs:\n",
    "                        display(HTML(f\"<h4>{prio} {self.t('recommendations')}</h4>\"))\n",
    "                        for i, rec in enumerate(recs, 1):\n",
    "                            risk_badge = f\"<span style='background: #e9ecef; padding: 2px 8px; border-radius: 12px; font-size: 0.8em; margin-left: 10px;'>{rec['risk']}</span>\"\n",
    "                            display(HTML(f\"<div style='background: white; padding: 10px 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #1f77b4;'><b>{i}.</b> {rec['text']} {risk_badge}</div>\"))\n",
    "                \n",
    "                # Add action buttons\n",
    "                display(HTML(f\"\"\"\n",
    "                <div style='margin-top: 20px; display: flex; gap: 10px;'>\n",
    "                    <button style='background-color: #4CAF50; color: white; padding: 10px 15px; border: none; border-radius: 5px; cursor: pointer;'>\n",
    "                        📧 {self.t('email_recommendations')}\n",
    "                    </button>\n",
    "                    <button style='background-color: #2196F3; color: white; padding: 10px 15px; border: none; border-radius: 5px; cursor: pointer;'>\n",
    "                        📊 {self.t('generate_action_plan')}\n",
    "                    </button>\n",
    "                    <button style='background-color: #FF9800; color: white; padding: 10px 15px; border: none; border-radius: 5px; cursor: pointer;'>\n",
    "                        📋 {self.t('export_pdf')}\n",
    "                    </button>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "        \n",
    "        # Set up event handlers\n",
    "        def update_recommendations(change):\n",
    "            show_recommendations(rec_district.value, priority_filter.value, risk_type_filter.value)\n",
    "        \n",
    "        rec_district.observe(update_recommendations, names='value')\n",
    "        priority_filter.observe(update_recommendations, names='value')\n",
    "        risk_type_filter.observe(update_recommendations, names='value')\n",
    "        \n",
    "        # Display the two-column layout\n",
    "        display(widgets.HBox([rec_left, rec_right]))\n",
    "        update_recommendations(None)  # Initial call\n",
    "    \n",
    "    def create_chat_tab(self):\n",
    "        \"\"\"Create the chat tab content\"\"\"\n",
    "        display(HTML(f\"<h2 style='color:#1f77b4; text-align:center;'>{self.t('chat_tab')}</h2>\"))\n",
    "        \n",
    "        # Create chat interface\n",
    "        chat_container = widgets.VBox(layout=widgets.Layout(width='100%', padding='10px'))\n",
    "        \n",
    "        # Chat history\n",
    "        chat_history = widgets.Output(layout=widgets.Layout(height='400px', overflow_y='auto'))\n",
    "        \n",
    "        # Input area\n",
    "        input_area = widgets.HBox(layout=widgets.Layout(width='100%', margin='10px 0'))\n",
    "        \n",
    "        # Chat input\n",
    "        chat_input = widgets.Text(\n",
    "            value='',\n",
    "            placeholder=self.t('chat_placeholder'),\n",
    "            description='Question:',\n",
    "            disabled=False,\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        \n",
    "        # Send button\n",
    "        send_button = widgets.Button(\n",
    "            description=self.t('send'),\n",
    "            button_style='primary',\n",
    "            tooltip='Send your question',\n",
    "            layout=widgets.Layout(width='20%')\n",
    "        )\n",
    "        \n",
    "        # Suggestion chips\n",
    "        suggestions = [\n",
    "            \"What is the average rainfall in Hyderabad?\",\n",
    "            \"Which district has the highest risk?\",\n",
    "            \"What recommendations do you have for Adilabad?\",\n",
    "            \"Show me drought risk trends\",\n",
    "            \"Compare flood risk between districts\"\n",
    "        ]\n",
    "        \n",
    "        # Create suggestion buttons\n",
    "        suggestion_buttons = []\n",
    "        for suggestion in suggestions:\n",
    "            btn = widgets.Button(\n",
    "                description=suggestion,\n",
    "                layout=widgets.Layout(width='auto', margin='0 5px 5px 0'),\n",
    "                style=widgets.ButtonStyle(button_color='#e9ecef')\n",
    "            )\n",
    "            # Set up click handler\n",
    "            def on_suggestion_click(btn, suggestion_text=suggestion):\n",
    "                chat_input.value = suggestion_text\n",
    "            \n",
    "            btn.on_click(on_suggestion_click)\n",
    "            suggestion_buttons.append(btn)\n",
    "        \n",
    "        # Arrange buttons in a wrapping box\n",
    "        suggestions_box = widgets.HBox(\n",
    "            children=suggestion_buttons, \n",
    "            layout=widgets.Layout(flex_flow='row wrap', justify_content='flex-start')\n",
    "        )\n",
    "        \n",
    "        # Add to input area\n",
    "        input_area.children = [chat_input, send_button]\n",
    "        \n",
    "        # Add to chat container\n",
    "        chat_container.children = [chat_history, widgets.HTML(value=f\"<p><b>{self.t('suggestions')}</b></p>\"), suggestions_box, input_area]\n",
    "        \n",
    "        # Display chat container\n",
    "        display(chat_container)\n",
    "        \n",
    "        # Chat functionality\n",
    "        chat_data = []\n",
    "        \n",
    "        def add_message(sender, message):\n",
    "            timestamp = datetime.now().strftime(\"%H:%M\")\n",
    "            if sender == 'user':\n",
    "                chat_data.append({'sender': 'user', 'message': message, 'time': timestamp})\n",
    "                with chat_history:\n",
    "                    display(HTML(f\"\"\"\n",
    "                    <div class=\"user-message\">\n",
    "                        <div style=\"font-weight: bold;\">You ({timestamp})</div>\n",
    "                        <div>{message}</div>\n",
    "                    </div>\n",
    "                    \"\"\"))\n",
    "            else:\n",
    "                chat_data.append({'sender': 'bot', 'message': message, 'time': timestamp})\n",
    "                with chat_history:\n",
    "                    display(HTML(f\"\"\"\n",
    "                    <div class=\"bot-message\">\n",
    "                        <div style=\"font-weight: bold;\">{self.t('climate_assistant')} ({timestamp})</div>\n",
    "                        <div>{message}</div>\n",
    "                    </div>\n",
    "                    \"\"\"))\n",
    "            \n",
    "            # Scroll to bottom after adding message\n",
    "            display(Javascript(\"\"\"\n",
    "                var chatHistory = document.querySelector('.jp-OutputArea-output');\n",
    "                if (chatHistory) {\n",
    "                    chatHistory.scrollTop = chatHistory.scrollHeight;\n",
    "                }\n",
    "            \"\"\"))\n",
    "        \n",
    "        # Enhanced semantic query function with better responses\n",
    "        def enhanced_semantic_query(question):\n",
    "            # Define responses with more detail\n",
    "            responses = {\n",
    "                \"what is the average rainfall in hyderabad\": \n",
    "                    \"The average annual rainfall in Hyderabad is approximately 750 mm, with most rainfall occurring during the monsoon season (June-September). The city experiences significant variation, with some years receiving as much as 900 mm and others as little as 500 mm.\",\n",
    "                \"which district has the highest risk\": \n",
    "                    \"Mahabubnagar currently has the highest climate risk score (9.1/10) due to its high vulnerability to drought and agricultural stress. The district has experienced significant crop failures in recent years due to irregular rainfall patterns.\",\n",
    "                \"what recommendations do you have for adilabad\": \n",
    "                    \"For Adilabad, I recommend: 1) Implementing water conservation measures like check dams and percolation tanks, 2) Developing early warning systems for heatwaves, and 3) Promoting drought-resistant crops in agricultural planning. The district has high drought vulnerability, so water management is crucial.\",\n",
    "                \"show me drought risk trends\": \n",
    "                    \"Drought risk has been increasing across Telangana over the past decade. The western districts like Mahabubnagar and Medak show the highest increase at approximately 2.3% per year. This trend correlates with decreasing monsoon rainfall and increasing temperatures during the summer months.\",\n",
    "                \"compare flood risk between districts\": \n",
    "                    \"Flood risk varies significantly across districts. Hyderabad has the highest urban flood risk due to impermeable surfaces and drainage challenges. Coastal districts like Khammam have higher riverine flood risk. In comparison, western districts like Adilabad have minimal flood risk but higher drought vulnerability.\",\n",
    "                \"default\": \n",
    "                    \"I'm sorry, I don't have specific information on that question. I can help you with questions about rainfall, temperature, risk assessments, and recommendations for specific districts. Try asking about a specific district or climate factor.\"\n",
    "            }\n",
    "            \n",
    "            # Find the best matching question\n",
    "            question_lower = question.lower()\n",
    "            best_match = \"default\"\n",
    "            for key in responses:\n",
    "                if key in question_lower:\n",
    "                    best_match = key\n",
    "                    break\n",
    "            \n",
    "            # Sometimes add a follow-up question to make it more conversational\n",
    "            follow_ups = [\n",
    "                \" Would you like more detailed information about this?\",\n",
    "                \" Is there a specific aspect you'd like to explore further?\",\n",
    "                \" I can provide a detailed report if you're interested.\",\n",
    "                \" Let me know if you need recommendations for addressing this.\"\n",
    "            ]\n",
    "            \n",
    "            response = responses[best_match] + random.choice(follow_ups)\n",
    "            return response\n",
    "        \n",
    "        # Send message function\n",
    "        def send_message(b=None):\n",
    "            question = chat_input.value\n",
    "            if question.strip():\n",
    "                add_message('user', question)\n",
    "                chat_input.value = ''\n",
    "                \n",
    "                # Get response immediately\n",
    "                response = enhanced_semantic_query(question)\n",
    "                add_message('bot', response)\n",
    "        \n",
    "        # Set up event handlers\n",
    "        send_button.on_click(send_message)\n",
    "        chat_input.on_submit(send_message)\n",
    "        \n",
    "        # Add welcome message\n",
    "        add_message('bot', f\"{self.t('hello')} {self.t('assist')}\")\n",
    "\n",
    "# Create and display the dashboard\n",
    "dashboard = EnhancedRTGSDashboard(df_clean, insights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
